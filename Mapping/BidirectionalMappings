install.packages("tidyverse") # includes ggplot2??
install.packages("ggplot2") # for general plots
install.packages("beeswarm") # for beeswarm plots
install.packages("colorspace") # for fixing colors in plots
install.packages("stargazer") # for pretty regression output tables
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages("sure") # package for calculating residuals for ordinal logistic regression (https://journal.r-project.org/archive/2018/RJ-2018-004/RJ-2018-004.pdf)
install.packages("mediation") # package for testing mediation effects
install.packages("gridExtra")


library(tidyverse) 
library(ggplot2)
library(beeswarm)
library(colorspace) 
library(stargazer)
library(MASS)
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(sure) 
library(mediation) 
library(gridExtra)


setwd("/Users/labuser/Documents/R")
getwd()

#LAPTOP setwd("~/Desktop")

Mapping <- read.csv("Mapping_Coding_CH_190809.csv", na.strings = "N/A")
 
typeof(Mapping) # when importing using read.csv, resulting obj type is a list (data frame)
View(Mapping)

####HEARING KIDS ONLY####

Map_HBE <- subset(Mapping, Mapping$Including.in.Study == 'Yes' & Mapping$Coded. == "Yes" & Mapping$Group_2cat == 'Hearing')
View(Map_HBE)
str(Map_HBE)

## MEDIAN AND SD FOR EACH MAPPING TYPE #
median(Map_HBE$SumTotal_QuantityWord)
sd(Map_HBE$SumTotal_QuantityWord, na.rm = TRUE)
median(Map_HBE$SumTotal_WordQuantity)
sd(Map_HBE$SumTotal_WordQuantity, na.rm = TRUE)
median(Map_HBE$SumTotal_QuantityNumeral)
sd(Map_HBE$SumTotal_QuantityNumeral, na.rm = TRUE)
median(Map_HBE$SumTotal_NumeralQuantity)
sd(Map_HBE$SumTotal_NumeralQuantity, na.rm = TRUE)
median(Map_HBE$SumTotal_WordNumeral)
sd(Map_HBE$SumTotal_WordNumeral, na.rm = TRUE)
median(Map_HBE$SumTotal_NumeralWord)
sd(Map_HBE$SumTotal_NumeralWord, na.rm = TRUE)

## ASYMMETRIES? ## 
  #QUANTITY-WORD#
      QW<-wilcox.test(Map_HBE$SumTotal_QuantityWord, Map_HBE$SumTotal_WordQuantity, paired = TRUE, exact=FALSE)
      QW
      QW_Zstat<-qnorm(QW$p.value/2)
      QW_Zstat
      abs(QW_Zstat)/sqrt(17)
      
  #QUANTITY-NUMERAL#
      QN<-wilcox.test(Map_HBE$SumTotal_QuantityNumeral, Map_HBE$SumTotal_NumeralQuantity, paired = TRUE, exact=FALSE)
      QN
      QN_Zstat<-qnorm(QN$p.value/2)
      QN_Zstat
      abs(QN_Zstat)/sqrt(17)
      
  #WORD-NUMERAL#
      WN<-wilcox.test(Map_HBE$SumTotal_WordNumeral, Map_HBE$SumTotal_NumeralWord, paired = TRUE, exact=FALSE)
      WN
      WN_Zstat<-qnorm(WN$p.value/2)
      WN_Zstat
      abs(WN_Zstat)/sqrt(17)
      
 
 ## HISTOGRAM OF DIFFERENCE SCORES FOR MAPPING PAIRS ##
     #Want columns to start at x axis, but solutions all include changing expand to start at 0. that would remove the blank columns.#
         DH_QW <- ggplot(Map_HBE, aes(x=Map_HBE$Difference_Quantity.Word_Word.Quantity)) + geom_bar(aes(y=..count../sum(..count..))) + labs(y="Proportion of Children", x="Quantity-Word > Word-Quantity") + theme(panel.background = element_blank(), text = element_text(size=12, family="Times New Roman")) + expand_limits(x = c(-8,9), y = c(0,1)) + scale_y_continuous(breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)) + scale_x_continuous(breaks=c(-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9)) + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.line = element_line(colour = "black")) 
         DH_QW

         DH_NW <- ggplot(Map_HBE, aes(x=Map_HBE$Difference_Numeral.Word_Word.Numeral)) + geom_bar(aes(y=..count../sum(..count..))) + labs(x="Numeral-Word > Word-Numeral") + theme(panel.background = element_blank(), axis.title.y=element_blank(), text = element_text(size=12, family="Times New Roman")) + expand_limits(x = c(-8,9), y = c(0,1)) + scale_y_continuous(breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)) + scale_x_continuous(breaks=c(-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9)) + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.line = element_line(colour = "black")) 
         DH_NW 

         DH_QN <- ggplot(Map_HBE, aes(x=Map_HBE$Difference_Quantity.Numeral_Numeral.Quantity)) + geom_bar(aes(y=..count../sum(..count..))) + labs(x="Quantity-Numeral > Numeral-Quantity")+ theme(panel.background = element_blank(), axis.title.y=element_blank(), text = element_text(size=12, family="Times New Roman")) + expand_limits(x = c(-8,9), y = c(0,1)) + scale_y_continuous(breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)) + scale_x_continuous(breaks=c(-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9)) + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.line = element_line(colour = "black")) 
         DH_QN

         grid.arrange(DH_QW, DH_NW, DH_QN, ncol = 3) 
         
     #SKEWNESS, KURTOSIS, MEAN,RANGE,SD,SE#
         install.packages(“psych”)
         library(psych)
         describe(Map_HBE$Difference_Quantity.Numeral_Numeral.Quantity)
         describe(Map_HBE$Difference_Quantity.Word_Word.Quantity)
         describe(Map_HBE$Difference_Numeral.Word_Word.Numeral)
         
         
     #PERCENT THAT FALLS BETWEEN 1 POINT#
         DiffQW <- Map_HBE$Difference_Quantity.Word_Word.Quantity
         QW_1 <- length(which(DiffQW >= 0 & DiffQW <= 2)) #number of observations that fall 1 point above or below DiffQW median of 1
         N <- nrow(Map_HBE) #gives # of observations
         (QW_1/N)*100

         DiffNW <- Map_HBE$Difference_Numeral.Word_Word.Numeral
         NW_1 <- length(which(DiffNW >= 0 & DiffNW <= 2)) #number of observations that fall 1 point above or below DiffNW median of 1
         N <- nrow(Map_HBE) #gives # of observations
         (NW_1/N)*100

         DiffQN <- Map_HBE$Difference_Quantity.Numeral_Numeral.Quantity
         QN_1 <- length(which(DiffQN >= 1 & DiffQN <= 3)) #number of observations that fall 1 point above or below DiffQN median of 2
         N <- nrow(Map_HBE) #gives # of observations
         (QN_1/N)*100



 ## IF SEPARATING BY AGE GROUPS ##
Map_HBE$AgeGrp <- ifelse(Map_HBE$Age_Rounded < 6, "5-year-olds", "6 and up")
Map5 <- subset(Map_HBE, Map_HBE$AgeGrp =="5-year-olds")
Map6up <- subset(Map_HBE, Map_HBE$AgeGrp =="6 and up")

 #GRAPH OF ACCURACY SCORES BY MAPPING PAIRS AND AGE#
       Map5$Sum_Quantity.Numeral_Numeral.Quantity
       Map6up$$Sum_Quantity.Numeral_Numeral.Quantity
       Map5$Sum_Numeral.Word_Word.Numeral
       Map6up$Sum_Numeral.Word_Word.Numeral
       Map5$Sum_Quantity.Word_Word.Quantity
       Map6up$Sum_Quantity.Word_Word.Quantity
 
 
 
 

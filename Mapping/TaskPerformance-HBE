#Mapping Analyses, following Hurst Analyses


##If any of the following not already imported need import.packages("[packagename]")

install.packages("tidyverse") # includes ggplot2??
install.packages("ggplot2") # for general plots
install.packages("beeswarm") # for beeswarm plots
install.packages("colorspace") # for fixing colors in plots
install.packages("stargazer") # for pretty regression output tables
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages("sure") # package for calculating residuals for ordinal logistic regression (https://journal.r-project.org/archive/2018/RJ-2018-004/RJ-2018-004.pdf)
install.packages("mediation") # package for testing mediation effects
install.packages("gridExtra")
install.packages(“coin”)

library(tidyverse) 
library(ggplot2)
library(beeswarm)
library(colorspace) 
library(stargazer)
library(MASS)
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(sure) 
library(mediation) 
library(gridExtra)
library(coin)

setwd("~/Desktop")
getwd()

Mapping <- read.csv("Mapping_Coding_CH_191119.csv", na.strings = "N/A")
 
typeof(Mapping) # when importing using read.csv, resulting obj type is a list (data frame)
View(Mapping)

####HEARING KIDS ONLY####

Map_HBE <- subset(Mapping, Mapping$Including.in.Study == 'Yes' & Mapping$Coded. == "Yes" & Mapping$Hearing_Cat == 'Hearing')
View(Map_HBE)
str(Map_HBE)

#Q1: What does mapping performance look like with this age range (5-9)?
  
  #Proportion Correct for each Mapping Type (all HBE kids)
  qn <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Quantity.Numeral)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Quantity-Numeral") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  nq <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Numeral.Quantity)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Numeral-Quantity") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))

  wn <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Word.Numeral)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Word-Numeral") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  nw <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Numeral.Word)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Numeral-Word") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))

  qw <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Quantity.Word)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Quantity-Word") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  wq <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Word.Quantity)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Word-Quantity") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  
  grid.arrange(qw,nw,qn,wq,wn,nq, ncol = 3)


# COMPARE each type to chance - Hurst et al used one-sample Wilcoxon Signed Rank tests (use median and assume roughly normal distribution around MEDIAN)
  wilcox.test(Map_HBE$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #p-value = 3.211e-09, YES
  wilcox.test(Map_HBE$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #p-value = 3.813e-09, YES
  wilcox.test(Map_HBE$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #p-value = 2.702e-09, YES
  wilcox.test(Map_HBE$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #p-value = 6.062e-09, YES
  wilcox.test(Map_HBE$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #p-value = 2.301e-09, YES
  wilcox.test(Map_HBE$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #p-value = 4.516e-10, YES
#GOOD. ALL SIG ABOVE CHANCE. 

# get average RAW NUMBER correct for each mapping type across all kids 
MapAvgCorr <- colMeans(subset(Map_HBE, select = c(SumTotal_QuantityNumeral, SumTotal_NumeralQuantity, SumTotal_QuantityWord, SumTotal_WordQuantity, SumTotal_NumeralWord, SumTotal_WordNumeral)), na.rm = TRUE)
MapAvgCorr

# Mapping types are out of different numbers, so to calculate proportion correct need code below
MapMeans <- c((MapAvgCorr[1]/9), (MapAvgCorr[2]/8), (MapAvgCorr[3]/9), (MapAvgCorr[4]/8), (MapAvgCorr[5]/9), (MapAvgCorr[6]/8))
MapMeans


## 5 and 6 YO vs 7 and UP ##

##AGE GROUPS DECISONS ##
AGEGRP <- Map_HBE$AgeGrp %>% mutate(AGEGRP = case_when(Map_HBE$Age_Rounded >= 5  & Map_HBE$Age_Rounded < 6 ~ '5', Map_HBE$Age_Rounded >= 6  & Map_HBE$Age_Rounded < 7 ~ '6', Map_HBE$Age_Rounded >= 7  & Map_HBE$Age_Rounded < 8 ~ '7', Map_HBE$Age_Rounded >= 8  & Map_HBE$Age_Rounded < 9 ~ '8', Map_HBE$Age_Rounded >= 9  & Map_HBE$Age_Rounded < 10 ~ '9'))
Map_HBE2 <- cbind(Map_HBE, AGEGRP)
View(Map_HBE2)
YO5 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="5")
YO6 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="6")
YO7 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="7")
YO8 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="8")
YO9 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="9")
t.test(YO5$AvgCorrect_Total, YO6$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  #t = -1.3824, df = 18.414, p-value = 0.1834, 5 vs 6 NOT
t.test(YO5$AvgCorrect_Total, YO7$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  # 6 vs 7 SIG DIFFERENT
t.test(YO7$AvgCorrect_Total, YO8$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #7 vs 8 NOT 
t.test(YO7$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #7 vs 9 NOT
t.test(YO8$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #8 vs 9 NOT
t.test(YO6$AvgCorrect_Total, YO8$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") # t = -2.2195, df = 8.8544, p-value = 0.05408, BARELY NOT SIG
t.test(YO6$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #SIG DIFF
# SIG FINDINGS: 5 vs 6 NO, 6 vs 7 YES, 7 vs 8 NO, 7 vs 9 NO, 8 vs 9 NO, 6 vs 8 NO (but barely p = 0.054), 6 vs 9 YES… so good support for 5 and 6 year olds vs 7 year olds and up

#SETTING UP
#create a column for age group
Map_HBE$AgeGrp <- ifelse(Map_HBE$Age_Rounded < 7, "5- and 6-year-olds", "7 and up")

Map56 <- subset(Map_HBE, Map_HBE$AgeGrp =="5- and 6-year-olds")
Map7up <- subset(Map_HBE, Map_HBE$AgeGrp =="7 and up")

#RAW NUMBER correct & PROPORTION correct, THESE ARE FOR TABLES
Map56AvgCorr <- colMeans(subset(Map56, select = c(SumTotal_QuantityNumeral, SumTotal_NumeralQuantity, SumTotal_QuantityWord, SumTotal_WordQuantity, SumTotal_NumeralWord, SumTotal_WordNumeral)), na.rm = TRUE) 
Map56AvgCorr
Map56Means <- c((Map56AvgCorr[1]/9), (Map56AvgCorr[2]/8), (Map56AvgCorr[3]/9), (Map56AvgCorr[4]/8), (Map56AvgCorr[5]/9), (Map56AvgCorr[6]/8))
Map56Means

Map7upAvgCorr <- colMeans(subset(Map7up, select = c(SumTotal_QuantityNumeral, SumTotal_NumeralQuantity, SumTotal_QuantityWord, SumTotal_WordQuantity, SumTotal_NumeralWord, SumTotal_WordNumeral)), na.rm = TRUE) 
Map7upAvgCorr
Map7Means <- c((Map7upAvgCorr[1]/9), (Map7upAvgCorr[2]/8), (Map7upAvgCorr[3]/9), (Map7upAvgCorr[4]/8), (Map7upAvgCorr[5]/9), (Map7upAvgCorr[6]/8))
Map7Means

#ALL SIGNIFICANTLY DIFFERENT FROM CHANCE?, THESE ARE FOR SIGNIFICANCE ON TABLES
# 5 and 6 YO 
wilcox.test(Map56$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, p-value = 2.54e-05
wilcox.test(Map56$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, p-value = 2.784e-05
wilcox.test(Map56$SumTotal_QuantityNumeral, Map56$SumTotal_NumeralQuantity, paired=TRUE, exact=FALSE) # ASYMMETRY? Quantity numeral better than numeral quantity? 
#YES, p-value = p-value = 0.001521

wilcox.test(Map56$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, p-value = 2.612e-05
wilcox.test(Map56$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, p-value = 2.956e-05
wilcox.test(Map56$SumTotal_QuantityWord, Map56$SumTotal_WordQuantity, paired=TRUE, exact=FALSE) # ASYMMETRY? Quantity word better than word quantity?
#YES, p-value = 0.0009956

wilcox.test(Map56$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, p-value = 1.905e-05
wilcox.test(Map56$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, p-value = 1.396e-05
wilcox.test(Map56$SumTotal_NumeralWord, Map56$SumTotal_WordNumeral, paired=TRUE, exact=FALSE) # ASYMMETRY?  Numeral word better than word numeral?
#YES, p-value = 0.0002018

# 7 YO & >

wilcox.test(Map7up$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, V = 231, p-value = 7.534e-06
wilcox.test(Map7up$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, V = 231, p-value = 1.204e-05
wilcox.test(Map7up$SumTotal_QuantityNumeral, Map7up$SumTotal_NumeralQuantity, paired=TRUE, exact=FALSE) # ASYMMETRY? Quantity numeral better than numeral quantity?
#YES, V = 190, p-value = 6.333e-05

wilcox.test(Map7up$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, V = 231, p-value = 7.573e-06
wilcox.test(Map7up$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, V = 231, p-value = 1.925e-05
wilcox.test(Map7up$SumTotal_QuantityWord, Map7up$SumTotal_WordQuantity, paired=TRUE, exact=FALSE) # ASYMMETRY? Quantity word better than word quantity?
#YES, V = 210, p-value = 4.749e-05

wilcox.test(Map7up$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, V = 210, p-value = 1.255e-05
wilcox.test(Map7up$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) #YES, V = 231, p-value = 2.525e-06
wilcox.test(Map7up$SumTotal_NumeralWord, Map7up$SumTotal_WordNumeral, paired=TRUE, exact=FALSE) # ASYMMETRY?  Numeral word better than word numeral?
#YES, V = 231, p-value = 1.952e-05

## SEPARATE INTO SMALL (1-3), MEDIUM (4-5), LARGE (6-9) QUANTITIES BY AGE, OVERALL NOT SEPARATED BY MAPPINGS ##
     #SMALL:
          #Target 1: Items 1, 10, 18, 35, 44
          #Target 2: Items 2, 19, 27, 36
          #Target 3: Items 6, 15, 26, 29, 41, 47
     #MEDIUM:
          #Target 4: Items 5, 11, 21, 32, 39, 51
          #Target 5: Items 8, 12, 23, 34, 37, 50
     #LARGE:
          #Target 6: Items 3, 16, 24, 31, 43, 49
          #Target 7: Items 9, 14, 22, 30, 38, 46
          #Target 8: Items 7, 17, 25, 28, 40, 48
          #Target 9: Items 4, 13, 20, 33, 42, 45

     # AGES 5 #
     Map56_Sm_AvgCorr <- colMeans(subset(Map56, select = c(Item1_Correct.,Item10_Correct.,Item18_Correct.,Item35_Correct., Item44_Correct.,Item2_Correct.,Item19_Correct.,Item27_Correct.,Item36_Correct.,Item6_Correct.,Item15_Correct.,Item26_Correct.,Item29_Correct.,Item41_Correct.,Item47_Correct.)), na.rm = TRUE) 
     wilcox.test(Map56_Sm_AvgCorr, mu = .25, alternative = "greater") #is mean of small quantities correct for ages 5 and 6 significantly greater than chance (0.25) 
     #YES, V = 120, p-value = 0.0003031
     Map56_Med_AvgCorr <- colMeans(subset(Map56, select = c(Item5_Correct.,Item11_Correct.,Item21_Correct.,Item32_Correct., Item39_Correct.,Item51_Correct.,Item8_Correct.,Item12_Correct.,Item23_Correct.,Item34_Correct.,Item37_Correct.,Item50_Correct.)), na.rm = TRUE) 
     wilcox.test(Map56_Med_AvgCorr, mu = .25, alternative = "greater") #is mean of medium quantities correct for ages 5 and 6 significantly greater than chance (0.25) 
     #YES, V = 78, p-value = 0.001215
     Map56_Lrg_AvgCorr <- colMeans(subset(Map56, select = c(Item3_Correct.,Item16_Correct.,Item24_Correct.,Item31_Correct., Item43_Correct.,Item49_Correct.,Item9_Correct.,Item14_Correct.,Item22_Correct.,Item30_Correct.,Item38_Correct.,Item46_Correct., Item46_Correct., Item7_Correct., Item17_Correct., Item25_Correct.,Item28_Correct., Item40_Correct., Item48_Correct.,Item4_Correct.,Item13_Correct.,Item20_Correct.,Item33_Correct.,Item42_Correct.,Item45_Correct.)), na.rm = TRUE) 
     wilcox.test(Map56_Lrg_AvgCorr, mu = .25, alternative = "greater") #is mean of large quantities correct for ages 5 and 6 significantly greater than chance (0.25) 
     #YES, V = 325, p-value = 6.201e-06

     # AGES 7 & > #
     Map7up_Sm_AvgCorr <- colMeans(subset(Map7up, select = c(Item1_Correct.,Item10_Correct.,Item18_Correct.,Item35_Correct., Item44_Correct.,Item2_Correct.,Item19_Correct.,Item27_Correct.,Item36_Correct.,Item6_Correct.,Item15_Correct.,Item26_Correct.,Item29_Correct.,Item41_Correct.,Item47_Correct.)), na.rm = TRUE) 
     wilcox.test(Map7up_Sm_AvgCorr, mu = .25, alternative = "greater") #is mean of small quantities correct for ages 6 and > significantly greater than chance (0.25) 
     #YES, V = 120, p-value = 0.0001942
     Map7up_Med_AvgCorr <- colMeans(subset(Map7up, select = c(Item5_Correct.,Item11_Correct.,Item21_Correct.,Item32_Correct., Item39_Correct.,Item51_Correct.,Item8_Correct.,Item12_Correct.,Item23_Correct.,Item34_Correct.,Item37_Correct.,Item50_Correct.)), na.rm = TRUE) 
     wilcox.test(Map7up_Med_AvgCorr, mu = .25, alternative = "greater") #is mean of medium quantities correct for ages 6 and > significantly greater than chance (0.25) 
     #YES, V = 78, p-value = 0.001057
     Map7up_Lrg_AvgCorr <- colMeans(subset(Map7up, select = c(Item3_Correct.,Item16_Correct.,Item24_Correct.,Item31_Correct., Item43_Correct.,Item49_Correct.,Item9_Correct.,Item14_Correct.,Item22_Correct.,Item30_Correct.,Item38_Correct.,Item46_Correct., Item46_Correct., Item7_Correct., Item17_Correct., Item25_Correct.,Item28_Correct., Item40_Correct., Item48_Correct.,Item4_Correct.,Item13_Correct.,Item20_Correct.,Item33_Correct.,Item42_Correct.,Item45_Correct.)), na.rm = TRUE) 
     wilcox.test(Map7up_Lrg_AvgCorr, mu = .25, alternative = "greater") #is mean of large quantities correct for ages 5 significantly greater than chance (0.25) 
     #YES, V = 325, p-value = 4.969e-06
     
#### MADE CHANGES UP TO HERE!

## SEPARATE INTO SMALL (1-3), MEDIUM (4-5), LARGE (6-9) QUANTITIES BY AGE, SEPARATED BY MAPPING PAIRS ##
# AGES 5 # 
#SMALL#
wilcox.test(Map56$AvgCorrect_Sm_QW, mu = .25, alternative = "greater") # is mean quantity & word correct for small quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Sm_QW)
wilcox.test(Map5$AvgCorrect_Sm_QN, mu = .25, alternative = "greater") # is mean quantity & numeral correct for small quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Sm_QN)
wilcox.test(Map5$AvgCorrect_Sm_WN, mu = .25, alternative = "greater") # is mean word & numeral correct for small quantities & ages 5 and 6 significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Sm_WN)

#MEDIUM#
wilcox.test(Map5$AvgCorrect_Med_QW, mu = .25, alternative = "greater") # is mean quantity & word correct for medium quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Med_QW)
wilcox.test(Map5$AvgCorrect_Med_QN, mu = .25, alternative = "greater") # is mean quantity & numeral correct for medium quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Med_QN)
wilcox.test(Map5$AvgCorrect_Med_WN, mu = .25, alternative = "greater") # is mean word & numeral correct for medium quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Med_WN)

#LARGE#
wilcox.test(Map5$AvgCorrect_Lrg_QW, mu = .25, alternative = "greater") # is mean quantity & word correct for large  quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Lrg_QW)
wilcox.test(Map5$AvgCorrect_Lrg_QN, mu = .25, alternative = "greater") # is mean quantity & numeral correct for large quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Lrg_QN)
wilcox.test(Map5$AvgCorrect_Lrg_WN, mu = .25, alternative = "greater") # is mean word & numeral correct for large quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map5$AvgCorrect_Lrg_WN)

# AGES 6 and up # 
#SMALL#
wilcox.test(Map6up$AvgCorrect_Sm_QW, mu = .25, alternative = "greater") # is mean quantity & word correct for small quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Sm_QW)
wilcox.test(Map6up$AvgCorrect_Sm_QN, mu = .25, alternative = "greater") # is mean quantity & numeral correct for small quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Sm_QN)
wilcox.test(Map6up$AvgCorrect_Sm_WN, mu = .25, alternative = "greater") # is mean word & numeral correct for small quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Sm_WN)

#MEDIUM#
wilcox.test(Map6up$AvgCorrect_Med_QW, mu = .25, alternative = "greater") # is mean quantity & word correct for medium quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Med_QW)
wilcox.test(Map6up$AvgCorrect_Med_QN, mu = .25, alternative = "greater") # is mean quantity & numeral correct for medium quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Med_QN)
wilcox.test(Map6up$AvgCorrect_Med_WN, mu = .25, alternative = "greater") # is mean word & numeral correct for medium quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Med_WN)

#LARGE#
wilcox.test(Map6up$AvgCorrect_Lrg_QW, mu = .25, alternative = "greater") # is mean quantity & word correct for large  quantities & ages 5 and 6  significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Lrg_QW)
wilcox.test(Map6up$AvgCorrect_Lrg_QN, mu = .25, alternative = "greater") # is mean quantity & numeral correct for large quantities & ages 5 and 6 significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Lrg_QN)
wilcox.test(Map6up$AvgCorrect_Lrg_WN, mu = .25, alternative = "greater") # is mean word & numeral correct for large quantities & ages 5  and 6 significantly greater than chance (0.25) 
mean(Map6up$AvgCorrect_Lrg_WN)

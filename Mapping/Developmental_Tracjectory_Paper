# Install and Load Libraries 
install.packages("car")
install.packages("sm")
install.packages("ggplot2") # for general plots
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages ("olsrr") #for testing normality
install.packages("plyr") #for count and other cool things
install.packages("psych") #obtain descriptive statistics
install.packages("colorspace") # for fixing colors in plots
install.packages("stargazer") # for pretty regression output tables
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit 
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages("sure") # package for calculating residuals for ordinal logistic regression (https://journal.r-project.org/archive/2018/RJ-2018-004/RJ-2018-004.pdf)
install.packages("mediation") # package for testing mediation effects
install.packages("gridExtra")
install.packages(“coin”)
install.packages("dplyr")
install.packages("tidyr")
install.packages("lme4")
              
        

library(car)
library(sm)
library(ggplot2) 
library(MASS) 
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(olsrr)
library(plyr)
library(psych)
library(colorspace) 
library(stargazer)
library(MASS)
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(sure) 
library(mediation) 
library(gridExtra)
library(coin)
library(dplyr)
library(tidyr)
library(lme4)

# Check and Set Working Directory
      setwd("~/Desktop")
      getwd()
      
# Import Data [[make sure is most recent version and saved as csv]]
      Map <- read.csv("Mapping_Coding_KW_200401.csv", na.strings = "N/A")
      View(Map)
      # <- saves MC as an object, read.csv() imports it    
  
 # Participants

      Map_EE <- subset(Map, Map$Group_4cat == "English Early" & (Map$Age_Rounded>=5 & Map$Age_Rounded<10 | is.na(Map$Age_Rounded)))
      View(Map_EE) #50 total English Early kids within our age range (5-9)

      Total_Inc_Study <- subset(Map_EE, Map_EE$Including.in.Study == "Yes" & Map_EE$Mapping_Include. == "Yes")
      View(Total_Inc_Study)# 47 total kids included in study

      Total_Not_Inc_Study <- subset(Map_EE, Map_EE$Including.in.Study == "No" | Map_EE$Including.in.Study== "")
      nrow(Total_Not_Inc_Study)# 3 total kids not included in study

      Total_Blank_NA <- subset(Map_EE, Map_EE$Including.in.Study == "" | is.na(Map_EE$Including.in.Study))
      nrow(Total_Blank_NA) # 0 blanks or N/As

      Tested_Not_Inc <- subset(Map_EE, Map_EE$Including.in.Study != "Yes" & Map_EE$Date.Tested != "")
      nrow(Tested_Not_Inc)
      # 0 kids not included in study that were tested. 
      
       # Find observations with missing Age and SES values
            which(is.na(Total_Inc_Study$Age_Rounded)) # 0 observations missing Age value
            Missing_Age <- Total_Inc_Study[which(is.na(Total_Inc_Study$Age_Rounded)),3]
            nrow(Missing_Age)

            which(is.na(Total_Inc_Study$SES)) # 0 observations missing SES value
            Missing_SES <- Total_Inc_Study[which(is.na(Total_Inc_Study$SES)),3]
            nrow(Missing_SES)

            Incorrect_SES <- subset(Total_Inc_Study, Total_Inc_Study$SES < 3  & Total_Inc_Study$SES < 66 | Total_Inc_Study$SES_range_8_to_66 == "")
            nrow(Incorrect_SES) #No observations of SES < 3 or > 66
                   
        # SEX 
        sum(Total_Inc_Study$M.F=='Female') # 24
        sum(Total_Inc_Study$M.F=='Male') # 23
        sum(Total_Inc_Study$M.F=='N/A') # 0

        # RACE & ETHNICITY DESCRIPTIVE STATISTICS, grouped Unsure and N/As together
         count((Total_Inc_Study$Race)) #40 white, 3 mixed, 1 american indian/alaska native, 1 other, 1 unsure, 1 N/A
        count((Total_Inc_Study$Ethnicity)) #36 not hispanic or latino, 4 hispanic or latino, 6 N/A, 1 unsure

        # AGE DESCRIPTIVE STATISTICS    
        min(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 5.1
        max(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 9.7
        median(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 6.7
        mean(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 6.917021
        sd(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 1.304394
        range(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 5.1 - 9.7
        ggplot(Total_Inc_Study, aes(x=Group_4cat, y=Age_Rounded)) + geom_violin()

        # SES DESCRIPTIVE STATISTICS
        min(Total_Inc_Study$SES, na.rm=TRUE) # 17
        max(Total_Inc_Study$SES, na.rm=TRUE) # 66
        median(Total_Inc_Study$SES, na.rm=TRUE) # 61
        mean(Total_Inc_Study$SES, na.rm=TRUE) # 56.20213
        sd(Total_Inc_Study$SES, na.rm=TRUE) # 12.37005
        range(Total_Inc_Study$SES, na.rm=TRUE) # 17 - 66
        ggplot(Total_Inc_Study, aes(x=Group_4cat, y=SES)) + geom_violin()
            # Skewness and Kurtosis for SES 
                  describe(Total_Inc_Study$SES) #using Psych package, skewness -1.99 & SE 1.8
                  qplot(Total_Inc_Study$SES, geom = 'histogram', binwidth = 2) + xlab('SES') #highly skewed 

#Data Analysis
        Map_HBE <- subset(Map_EE, Map_EE$Including.in.Study == "Yes" & Map_EE$Mapping_Include. == "Yes") #RENAMING Total_Inc_Study DATA FRAME for coding ease
        View(Map_HBE)
        
        #Overall Mapping Performance
        wilcox.test(Map_HBE$AvgCorrect_Total, mu = .25, alternative = "greater") #overall mapping performance compared to chance, p-value = 1.129e-09
        
        All <- Map_HBE$SumCorrectTotal_All
        Ch <- 12.75 #51/4 (at chance score)
        Var_Ch <- length(which(All>= Ch)) #number of observations equal to or above chance
        N <- nrow(Map_HBE) #number of total observations
        (Var_Ch/N)*100 #100% at or above chance
        
        All <- Map_HBE$SumCorrectTotal_All
        C_All <- 51 #ceiling performance 
        Var_All <- length(which(All>= C_All)) #number of observations equal to ceiling 
        N <- nrow(Map_HBE) #number of total observations
        (Var_All/N)*100 #19% at ceiling
        
        #Mixed Effects Logistic Regression
              #Want wide → long, use tidyr's pivot_longer() 
              #resource https://cran.r-project.org/web/packages/tidyr/vignettes/pivot.html
                HBE_long <- pivot_longer(data = Map_HBE, cols=c(ends_with("Answer")), names_to = c("Type"), values_to = "Quantity")
                View(HBE_long) 
                HBE_long2 <- pivot_longer(data = Map_HBE, cols=c(ends_with("Correct.")), names_to = c("Type2"), values_to = "Correct")
                View(HBE_long2)
                HBE_longest <- cbind(HBE_long, HBE_long2)
                View(HBE_longest)
                HBE_short <- HBE_longest[,!grepl("^Item",names(HBE_longest))] # delete columns that contain “item” 
                View(HBE_short)
                which(colnames(HBE_short)=="Child_LanguageTested") #19th column
                which(colnames(HBE_short)=="Quantity") #73rd column, WANT TO KEEP THIS COLUMN 
                HBE_short <- HBE_short[, -c(19:72)] #removes unnecessary columns
                View(HBE_short)
                which(colnames(HBE_short)=="Comments.1") #20
                which(colnames(HBE_short)=="Sum_Numeral.Word_Word.Numeral.1") #90
                HBE_short <- HBE_short[, -c(20:90)] #removes unnecessary columns
                View(HBE_short)

                # From Type column, create a new column (Map_Pair)
                #Create new column for which IF HBE_short$Type contains “NW” or “WN”, assign value “Numeral-Word”
                Map_Pair <- c()
                for(i in 1:2397)
                     Map_Pair[i] <- ifelse(grepl("NW", HBE_short$Type[i]), "Numeral-Word", ifelse(grepl("WN", HBE_short$Type[i]), "Numeral-Word", ifelse(grepl("QN", HBE_short$Type[i]), "Quantity-Numeral", ifelse(grepl("NQ", HBE_short$Type[i]), "Quantity-Numeral", ifelse(grepl("QW", HBE_short$Type[i]), "Quantity-Word", ifelse(grepl("WQ", HBE_short$Type[i]), "Quantity-Word","bananas"))))))
                HBE_short <- cbind(HBE_short, Map_Pair)
                View(HBE_short)

                #From Quantity column, create Small, Med, Large
                # resource https://stackoverflow.com/questions/15016723/how-to-add-column-into-a-dataframe-based-on-condition 
                Set_Size <- c()
                Set_Size <- case_when(HBE_short$Quantity <= 3 ~ 'Small',
                                       HBE_short$Quantity > 3 & HBE_short$Quantity<= 5 ~ 'Medium',
                                       HBE_short$Quantity > 5 ~ 'Large')
                HBE_short <- cbind(HBE_short,Set_Size)
                View(HBE_short)
                
                
                #BASIC LOG REG CODE... NOT APPROPRIATE? NEED MIXED EFFECTS?
                #Run the regression, resource: https://stats.idre.ucla.edu/r/dae/logit-regression/
                REG <- glm(Correct ~ Age_Rounded + SES + Set_Size + Map_Pair + Race + Ethnicity + M.F, data = HBE_short, family = "binomial") 
                summary(REG)
                exp(fixef(REG)) #provides Odds Ratios
                #Testing Model Fit, AIC: 963.18
                with(REG, null.deviance - deviance) #206.6286
                with(REG, df.null - df.residual) #11, degrees of freedom for the difference between the two models is equal to the number of predictor variables in the mode
                with(REG, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)) #p-value = 3.127361e-38, likelihood ratio test, associated p-value of less than 0.001 tells us that our model as a whole fits significantly better than an empty model
                logLik(REG) #log likelihood, -469.5919 (df=12)
     
     #FOLLOWING MIXED EFFECTS CODE RUNNING, BUT LOTS OF ERRORS. Resource: https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/
        REG2 <- glmer(Correct ~ Age_Rounded + SES + Set_Size + Map_Pair + Race + Ethnicity + M.F +
                (1 | SUBJECT_ID), data = HBE_short, family = binomial, control = glmerControl(optimizer = "bobyqa"),
            nAGQ = 10)
        
        
#Age Group Decision
      AGEGRP <- Map_HBE %>% mutate(AGEGRP = case_when(Map_HBE$Age_Rounded >= 5  & Map_HBE$Age_Rounded < 6 ~ '5', Map_HBE$Age_Rounded >= 6  & Map_HBE$Age_Rounded < 7 ~ '6', Map_HBE$Age_Rounded >= 7  & Map_HBE$Age_Rounded < 8 ~ '7', Map_HBE$Age_Rounded >= 8  & Map_HBE$Age_Rounded < 9 ~ '8', Map_HBE$Age_Rounded >= 9  & Map_HBE$Age_Rounded < 10 ~ '9'))
      Map_HBE2 <- cbind(Map_HBE, AGEGRP)
      View(Map_HBE2)
      YO5 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="5")
      YO6 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="6")
      YO7 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="7")
      YO8 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="8")
      YO9 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="9")
      t.test(YO5$AvgCorrect_Total, YO6$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  # 5 vs 6 not Different, t = -1.9814, df = 19.599, p-value = 0.06175
      t.test(YO5$AvgCorrect_Total, YO7$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  #5 vs 7 SIG DIFFERENT, t = -3.6593, df = 22.555, p-value = 0.001337
      t.test(YO6$AvgCorrect_Total, YO7$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  #6 vs 7 not Different, t = -1.2263, df = 16.815, p-value = 0.237
      t.test(YO7$AvgCorrect_Total, YO8$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #7 vs 8 not Different, t = -0.69919, df = 10.37, p-value = 0.4998 
      t.test(YO7$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #7 vs 9 not Different, t = -1.041, df = 11.649, p-value = 0.319
      t.test(YO8$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #8 vs 9 not Different, t = -0.79799, df = 7.3601, p-value = 0.4499
      t.test(YO6$AvgCorrect_Total, YO8$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #6 vs 8 not Different, t = -2.0488, df = 9.8067, p-value = 0.06819
      t.test(YO6$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #6 vs 9 SIG DIFFERENT, t = -2.2875, df = 10.692, p-value = 0.04361
      #FINDINGS: Not sig different: 5 vs 6, 6 vs 7, 7 vs 8, 7 vs 9, 8 vs 9, 6 vs 8, 6 vs 9, SIG different: 5 vs 7, 6 vs 9 
      #Age Group decision: 5-6 year olds vs 7-9 year olds
      
#SEPARATING BY AGE GROUPS
  Map_HBE$AgeGrp <- ifelse(Map_HBE$Age_Rounded < 7, "5- and 6-year-olds", "7 and up")
  Map56 <- subset(Map_HBE, Map_HBE$AgeGrp =="5- and 6-year-olds")
  Map7up <- subset(Map_HBE, Map_HBE$AgeGrp =="7 and up")   
      
 ##GROUPED BAR PLOT##
      ##SOURCE: https://onunicornsandgenes.blog/2014/03/19/using-r-barplot-with-ggplot2/##
      ## 1. CREATE DF FOR AGE GRP 5 ##
      View(Map56)
      AgeGrp <- Map56$AgeGrp
      QW <- mean(Map56$Sum_Quantity.Word_Word.Quantity)
      NW <- mean(Map56$Sum_Numeral.Word_Word.Numeral)
      QN <- mean(Map56$Sum_Quantity.Numeral_Numeral.Quantity)
      age56 <- data.frame(AgeGrp, QW, NW,QN)
      age56.data <- melt(age56, id.vars='AgeGrp')
      View(age56.data)

      ## 2. CREATE DF FOR AGE GRP 6 > ##
      AgeGrp <- Map7up$AgeGrp
      QW <- mean(Map7up$Sum_Quantity.Word_Word.Quantity)
      NW <- mean(Map7up$Sum_Numeral.Word_Word.Numeral)
      QN <- mean(Map7up$Sum_Quantity.Numeral_Numeral.Quantity)
      age7 <- data.frame(AgeGrp, QW,NW,QN)
      age7.data <- melt(age7, id.vars='AgeGrp')
      View(age7.data)

      ## 3. MERGE 2 AGE GROUP DFS ##
      K <- merge(age56.data, age7.data, by=c("AgeGrp","variable","value"), all = T)
      names(K)[names(K) == "variable"] <- "Map"
      View(K)

      ## 4. CREATE NEW DATA FRAME WITH SEMS ##
          #AGE 5 and 6#         
          AgeGrp <- Map56$AgeGrp
          QW_SE <- std.error(Map56$Sum_Quantity.Word_Word.Quantity)
          NW_SE <- std.error(Map56$Sum_Numeral.Word_Word.Numeral)
          QN_SE <- std.error(Map56$Sum_Quantity.Numeral_Numeral.Quantity)
          SE_56 <- data.frame(AgeGrp, QW_SE, NW_SE, QN_SE)
          SE_56 <- melt(SE_56, id.vars='AgeGrp')
          View(SE_56)

         #AGE 7 and up#
         AgeGrp <- Map7up$AgeGrp
         QW_SE <- std.error(Map7up$Sum_Quantity.Word_Word.Quantity)
         NW_SE <- std.error(Map7up$Sum_Numeral.Word_Word.Numeral)
         QN_SE <- std.error(Map7up$Sum_Quantity.Numeral_Numeral.Quantity)
         SE_7 <- data.frame(AgeGrp, QW_SE, NW_SE, QN_SE)
         SE_7 <- melt(SE_7, id.vars='AgeGrp')
         View(SE_7)

      ## 5. MERGE 2 SEM DATA FRAMES & PREP TO MERGE WITH OTHER MERGED DF ##
      K2 <- merge(SE_56, SE_7, by=c("AgeGrp","variable","value"), all = T)
      View(K2)
      K2 <- data.frame(K2$AgeGrp, K2$value, K2$variable, K$Map)
      names(K2)[names(K2) == "K2.value"] <- "value"
      names(K2)[names(K2) == "K2.AgeGrp"] <- "AgeGrp"
      names(K2)[names(K2) == "K.Map"] <- "Map"
      names(K2)[names(K2) == "K2.variable"] <- "variable"
      View(K2)

      ## 6. MERGE PREVIOUSLY COMBINED DATAFRAME WITH SEM DATA FRAME ##
      BOOYAH <- merge(K, K2, by=c("AgeGrp","Map"), all = T)
      names(BOOYAH)[names(BOOYAH) == "value.x"] <- "mean"
      names(BOOYAH)[names(BOOYAH) == "value.y"] <- "sem"
      View(BOOYAH)

      ## 7. ADD COLUMNS FOR ERROR BARS ##
             lower <- BOOYAH$mean - BOOYAH$sem
             upper <- BOOYAH$mean + BOOYAH$sem
             BOOYAH<- cbind(BOOYAH, lower, upper)
             View(BOOYAH)

      ## 8. CREATE BAR PLOT ##
All_Bar <- ggplot(BOOYAH, aes(BOOYAH$Map, BOOYAH$mean)) + geom_bar(aes(fill = BOOYAH$AgeGrp), width = 0.6, position = position_dodge(width=0.7), stat="identity") + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds", "7-year-olds and older")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17), limits = c(0,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity and Numeral", "Quantity and Word", "Numeral and Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=12, family="Times New Roman"))
BARS <- All_Bar + geom_errorbar(aes(ymax=BOOYAH$upper, ymin=BOOYAH$lower, group=AgeGrp), width=.5, position=position_dodge(0.7), data=BOOYAH)
BARS

#TESTING SIGNIFICANCE BETWEEN BARS#
t.test(Map56$Sum_Quantity.Numeral_Numeral.Quantity, Map7up$Sum_Quantity.Numeral_Numeral.Quantity, paired = FALSE, alternative = "two.sided") 
t.test(Map56$Sum_Quantity.Word_Word.Quantity, Map7up$Sum_Quantity.Word_Word.Quantity, paired = FALSE, alternative = "two.sided")
t.test(Map56$Sum_Numeral.Word_Word.Numeral, Map7up$Sum_Numeral.Word_Word.Numeral, paired = FALSE, alternative = "two.sided") 

#BOX PLOT
 AgeGrp <- Map56$AgeGrp
 QW <- Map56$Sum_Quantity.Word_Word.Quantity
 NW <- Map56$Sum_Numeral.Word_Word.Numeral
 QN <- Map56$Sum_Quantity.Numeral_Numeral.Quantity
 age56 <- data.frame(AgeGrp, QW, NW,QN)
 age56.data <- melt(age56, id.vars='AgeGrp')
 View(age56.data)
 AgeGrp <- Map7up$AgeGrp
 QW <- Map7up$Sum_Quantity.Word_Word.Quantity
 NW <- Map7up$Sum_Numeral.Word_Word.Numeral
 QN <- Map7up$Sum_Quantity.Numeral_Numeral.Quantity
 age7 <- data.frame(AgeGrp, QW,NW,QN)
 age7.data <- melt(age7, id.vars='AgeGrp')
 View(age7.data)
 B <- merge(age56.data, age7.data, by=c("AgeGrp","variable","value"), all = T)
 names(B)[names(B) == "variable"] <- "Map"
 View(B)
All_BOX <- ggplot(B, aes(B$Map, B$value, fill=B$AgeGrp)) + geom_boxplot() + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds", "7 to 9-year-olds")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
All_BOX

#BOXPLOT AND VIOLIN#
dodge <- position_dodge(width = 0.5)
All_BV <- ggplot(B, aes(B$Map, B$value, fill=B$AgeGrp)) + geom_violin (position = dodge)+ geom_boxplot(width=0.2, position = dodge) + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds", "7 to 9-year-olds")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
All_BV


## ANOVAS ##
     ## BEFORE RUN, HAVE BOOYAH AS A DF FROM ABOVE CODE ##
     ## REMEMBER TYPE 2 IS FOR BETWEEN SUBJECTS ##
     
     replications(BOOYAH) # CHECK BALANCE OF THE DATA TO ENSURE CAN USE AOV FXN. AOV can be used for balanced & unbalanced, but to a certain extent#

     ## AGE GROUP (2 LEVELS) --> SUM SCORES? One-way ANOVA unbalanced (different sample sizes), between subjects design ##
     aov_age<- aov(BOOYAH$mean ~ BOOYAH$AgeGrp)
     summary(aov_age)
     tuk_age<- TukeyHSD(aov_age)
     tuk_age  #can see WHICH variables are significantly different#

     ## MAP PAIR (3 LEVELS) --> SUM SCORES? One-way ANOVA balanced, within subjects/repeated measures design ##
     aov_map<- aov(BOOYAH$mean ~ BOOYAH$Map)
     summary(aov_map)
     tuk_map<- TukeyHSD(aov_map)
     tuk_map #can see WHICH variables are significantly different#

     ## INTERACTION BETWEEN INDEPENDENT VARIABLES? ##
     ## Source: https://rcompanion.org/handbook/G_09.html ##
     install.packages("car")
     library(car)
     model = lm(BOOYAH$mean ~ BOOYAH$AgeGrp + BOOYAH$Map + BOOYAH$AgeGrp:BOOYAH$Map, data = BOOYAH)
     anova(model)
     
     
     ## ETA-SQUARED, WITH ANOVA=TRUE CAN OBTAIN ANOVA TABLES AS WELL, DOUBLE CHECK ##
     # SOURCE: https://cran.r-project.org/web/packages/lsr/lsr.pdf #
     install.packages("lsr")
     library(lsr)
     
     etaSquared(aov_age,type = 1, anova = TRUE)
     etaSquared(aov_map,type = 1, anova = TRUE)
     etaSquared(model,type = 2, anova = TRUE)
     
     #REGRESSION FOR SES ON MAPPING PERFORMANCE
     SES <- Total_Inc_Study$SES_range_8_to_66 
     REG = lm(Total_Inc_Study$SumCorrectTotal_All ~ SES, data =Total_Inc_Study)
     anova(REG)
     etaSquared(REG,type = 1, anova = TRUE)
   

# Install and Load Libraries 
install.packages("car")
install.packages("sm")
install.packages("ggplot2") # for general plots
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages ("olsrr") #for testing normality
install.packages("plyr") #for count and other cool things
install.packages("psych") #obtain descriptive statistics
install.packages("colorspace") # for fixing colors in plots
install.packages("stargazer") # for pretty regression output tables
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit 
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages("sure") # package for calculating residuals for ordinal logistic regression (https://journal.r-project.org/archive/2018/RJ-2018-004/RJ-2018-004.pdf)
install.packages("mediation") # package for testing mediation effects
install.packages("gridExtra")
install.packages(“coin”)
install.packages("dplyr")
install.packages("tidyr")
install.packages("lme4")
install.packages("plotrix")
install.packages("VGAM") #for tobit model
              
        

library(car)
library(sm)
library(ggplot2) 
library(MASS) 
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(olsrr)
library(plyr)
library(psych)
library(colorspace) 
library(stargazer)
library(MASS)
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(sure) 
library(mediation) 
library(gridExtra)
library(coin)
library(dplyr)
library(tidyr)
library(lme4)
library("plotrix")
library(VGAM)

# Check and Set Working Directory
      setwd("~/Desktop")
      getwd()
      
# Import Data [[make sure is most recent version and saved as csv]]
      Map <- read.csv("Mapping_Coding_KW_200401.csv", na.strings = "N/A")
      View(Map)
      # <- saves MC as an object, read.csv() imports it    
  
 # Participants

      Map_EE <- subset(Map, Map$Group_4cat == "English Early" & (Map$Age_Rounded>=5 & Map$Age_Rounded<10 | is.na(Map$Age_Rounded)))
      View(Map_EE) #50 total English Early kids within our age range (5-9)

      Total_Inc_Study <- subset(Map_EE, Map_EE$Including.in.Study == "Yes" & Map_EE$Mapping_Include. == "Yes")
      View(Total_Inc_Study)# 47 total kids included in study

      Total_Not_Inc_Study <- subset(Map_EE, Map_EE$Including.in.Study == "No" | Map_EE$Including.in.Study== "")
      nrow(Total_Not_Inc_Study)# 3 total kids not included in study

      Total_Blank_NA <- subset(Map_EE, Map_EE$Including.in.Study == "" | is.na(Map_EE$Including.in.Study))
      nrow(Total_Blank_NA) # 0 blanks or N/As

      Tested_Not_Inc <- subset(Map_EE, Map_EE$Including.in.Study != "Yes" & Map_EE$Date.Tested != "")
      nrow(Tested_Not_Inc)
      # 0 kids not included in study that were tested. 
      
       # Find observations with missing Age and SES values
            which(is.na(Total_Inc_Study$Age_Rounded)) # 0 observations missing Age value
            Missing_Age <- Total_Inc_Study[which(is.na(Total_Inc_Study$Age_Rounded)),3]
            nrow(Missing_Age)

            which(is.na(Total_Inc_Study$SES)) # 0 observations missing SES value
            Missing_SES <- Total_Inc_Study[which(is.na(Total_Inc_Study$SES)),3]
            nrow(Missing_SES)

            Incorrect_SES <- subset(Total_Inc_Study, Total_Inc_Study$SES < 3  & Total_Inc_Study$SES < 66 | Total_Inc_Study$SES == "")
            nrow(Incorrect_SES) #No observations of SES < 3 or > 66
                   
        # SEX 
        sum(Total_Inc_Study$M.F=='Female') # 24
        sum(Total_Inc_Study$M.F=='Male') # 23
        sum(Total_Inc_Study$M.F=='N/A') # 0

        # RACE & ETHNICITY DESCRIPTIVE STATISTICS, grouped Unsure and N/As together
         count((Total_Inc_Study$Race)) #40 white, 3 mixed, 1 american indian/alaska native, 1 other, 1 unsure, 1 N/A
        count((Total_Inc_Study$Ethnicity)) #36 not hispanic or latino, 4 hispanic or latino, 6 N/A, 1 unsure

        # AGE DESCRIPTIVE STATISTICS    
        min(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 5.1
        max(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 9.7
        median(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 6.7
        mean(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 6.917021
        sd(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 1.304394
        range(Total_Inc_Study$Age_Rounded, na.rm=TRUE) # 5.1 - 9.7
        ggplot(Total_Inc_Study, aes(x=Group_4cat, y=Age_Rounded)) + geom_violin()

        # SES DESCRIPTIVE STATISTICS
        min(Total_Inc_Study$SES, na.rm=TRUE) # 17
        max(Total_Inc_Study$SES, na.rm=TRUE) # 66
        median(Total_Inc_Study$SES, na.rm=TRUE) # 61
        mean(Total_Inc_Study$SES, na.rm=TRUE) # 56.20213
        sd(Total_Inc_Study$SES, na.rm=TRUE) # 12.37005
        range(Total_Inc_Study$SES, na.rm=TRUE) # 17 - 66
        ggplot(Total_Inc_Study, aes(x=Group_4cat, y=SES)) + geom_violin()
            # Skewness and Kurtosis for SES 
                  describe(Total_Inc_Study$SES) #using Psych package, skewness -1.99 & SE 1.8
                  qplot(Total_Inc_Study$SES, geom = 'histogram', binwidth = 2) + xlab('SES') #highly skewed 

#Data Analysis
        Map_HBE <- subset(Map_EE, Map_EE$Including.in.Study == "Yes" & Map_EE$Mapping_Include. == "Yes") #RENAMING Total_Inc_Study DATA FRAME for coding ease
        View(Map_HBE)
        
        #Overall Mapping Performance
        wilcox.test(Map_HBE$AvgCorrect_Total, mu = .25, alternative = "greater") #overall mapping performance compared to chance, p-value = 1.129e-09
        
        All <- Map_HBE$SumCorrectTotal_All
        Ch <- 12.75 #51/4 (at chance score)
        Var_Ch <- length(which(All>= Ch)) #number of observations equal to or above chance
        N <- nrow(Map_HBE) #number of total observations
        (Var_Ch/N)*100 #100% at or above chance
        
        All <- Map_HBE$SumCorrectTotal_All
        C_All <- 51 #ceiling performance 
        Var_All <- length(which(All>= C_All)) #number of observations equal to ceiling 
        N <- nrow(Map_HBE) #number of total observations
        (Var_All/N)*100 #19% at ceiling
        
        #Mixed Effects Logistic Regression
              #Want wide → long, use tidyr's pivot_longer() 
              #resource https://cran.r-project.org/web/packages/tidyr/vignettes/pivot.html
                HBE_long <- pivot_longer(data = Map_HBE, cols=c(ends_with("Answer")), names_to = c("Type"), values_to = "Quantity")
                View(HBE_long) 
                HBE_long2 <- pivot_longer(data = Map_HBE, cols=c(ends_with("Correct.")), names_to = c("Type2"), values_to = "Correct")
                View(HBE_long2)
                HBE_longest <- cbind(HBE_long, HBE_long2)
                View(HBE_longest)
                HBE_short <- HBE_longest[,!grepl("^Item",names(HBE_longest))] # delete columns that contain “item” 
                View(HBE_short)
                which(colnames(HBE_short)=="Child_LanguageTested") #19th column
                which(colnames(HBE_short)=="Quantity") #73rd column, WANT TO KEEP THIS COLUMN 
                HBE_short <- HBE_short[, -c(19:72)] #removes unnecessary columns
                View(HBE_short)
                which(colnames(HBE_short)=="Comments.1") #20
                which(colnames(HBE_short)=="Sum_Numeral.Word_Word.Numeral.1") #90
                HBE_short <- HBE_short[, -c(20:90)] #removes unnecessary columns
                View(HBE_short)

                # From Type column, create a new column (Map_Pair)
                #Create new column for which IF HBE_short$Type contains “NW” or “WN”, assign value “Numeral-Word”
                Map_Pair <- c()
                for(i in 1:2397)
                     Map_Pair[i] <- ifelse(grepl("NW", HBE_short$Type[i]), "Numeral-Word", ifelse(grepl("WN", HBE_short$Type[i]), "Numeral-Word", ifelse(grepl("QN", HBE_short$Type[i]), "Quantity-Numeral", ifelse(grepl("NQ", HBE_short$Type[i]), "Quantity-Numeral", ifelse(grepl("QW", HBE_short$Type[i]), "Quantity-Word", ifelse(grepl("WQ", HBE_short$Type[i]), "Quantity-Word","bananas"))))))
                HBE_short <- cbind(HBE_short, Map_Pair)
                View(HBE_short)

                #From Quantity column, create Small, Med, Large
                # resource https://stackoverflow.com/questions/15016723/how-to-add-column-into-a-dataframe-based-on-condition 
                Set_Size <- c()
                Set_Size <- case_when(HBE_short$Quantity <= 3 ~ 'Small',
                                       HBE_short$Quantity > 3 & HBE_short$Quantity<= 5 ~ 'Medium',
                                       HBE_short$Quantity > 5 ~ 'Large')
                HBE_short <- cbind(HBE_short,Set_Size)
                View(HBE_short)
                
                
                #BASIC LOG REG CODE... NOT APPROPRIATE? NEED MIXED EFFECTS?
                #Run the regression, resource: https://stats.idre.ucla.edu/r/dae/logit-regression/
                REG <- glm(Correct ~ Age_Rounded + SES + Set_Size + Map_Pair + Race + Ethnicity + M.F, data = HBE_short, family = "binomial") 
                summary(REG)
                exp(fixef(REG)) #provides Odds Ratios
                #Testing Model Fit, AIC: 963.18
                with(REG, null.deviance - deviance) #206.6286
                with(REG, df.null - df.residual) #11, degrees of freedom for the difference between the two models is equal to the number of predictor variables in the mode
                with(REG, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)) #p-value = 3.127361e-38, likelihood ratio test, associated p-value of less than 0.001 tells us that our model as a whole fits significantly better than an empty model
                logLik(REG) #log likelihood, -469.5919 (df=12)
     
     #FOLLOWING MIXED EFFECTS CODE RUNNING, BUT LOTS OF ERRORS. Resource: https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/
        REG2 <- glmer(Correct ~ Age_Rounded + SES + Set_Size + Map_Pair + Race + Ethnicity + M.F +
                (1 | SUBJECT_ID), data = HBE_short, family = binomial, control = glmerControl(optimizer = "bobyqa"),
            nAGQ = 10)
        
        
#Age Group Decision
      AGEGRP <- Map_HBE %>% mutate(AGEGRP = case_when(Map_HBE$Age_Rounded >= 5  & Map_HBE$Age_Rounded < 6 ~ '5', Map_HBE$Age_Rounded >= 6  & Map_HBE$Age_Rounded < 7 ~ '6', Map_HBE$Age_Rounded >= 7  & Map_HBE$Age_Rounded < 8 ~ '7', Map_HBE$Age_Rounded >= 8  & Map_HBE$Age_Rounded < 9 ~ '8', Map_HBE$Age_Rounded >= 9  & Map_HBE$Age_Rounded < 10 ~ '9'))
      Map_HBE2 <- cbind(Map_HBE, AGEGRP)
      View(Map_HBE2)
      YO5 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="5")
      YO6 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="6")
      YO7 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="7")
      YO8 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="8")
      YO9 <- subset(Map_HBE2, Map_HBE2$AGEGRP =="9")
      t.test(YO5$AvgCorrect_Total, YO6$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  # 5 vs 6 not Different, t = -1.9814, df = 19.599, p-value = 0.06175
      t.test(YO5$AvgCorrect_Total, YO7$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  #5 vs 7 SIG DIFFERENT, t = -3.6593, df = 22.555, p-value = 0.001337
      t.test(YO6$AvgCorrect_Total, YO7$AvgCorrect_Total, paired = FALSE, alternative = "two.sided")  #6 vs 7 not Different, t = -1.2263, df = 16.815, p-value = 0.237
      t.test(YO7$AvgCorrect_Total, YO8$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #7 vs 8 not Different, t = -0.69919, df = 10.37, p-value = 0.4998 
      t.test(YO7$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #7 vs 9 not Different, t = -1.041, df = 11.649, p-value = 0.319
      t.test(YO8$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #8 vs 9 not Different, t = -0.79799, df = 7.3601, p-value = 0.4499
      t.test(YO6$AvgCorrect_Total, YO8$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #6 vs 8 not Different, t = -2.0488, df = 9.8067, p-value = 0.06819
      t.test(YO6$AvgCorrect_Total, YO9$AvgCorrect_Total, paired = FALSE, alternative = "two.sided") #6 vs 9 SIG DIFFERENT, t = -2.2875, df = 10.692, p-value = 0.04361
      #FINDINGS: Not sig different: 5 vs 6, 6 vs 7, 7 vs 8, 7 vs 9, 8 vs 9, 6 vs 8, 6 vs 9, SIG different: 5 vs 7, 6 vs 9 
      #Age Group decision: 5-6 year olds vs 7-9 year olds
      
#SEPARATING BY AGE GROUPS
  Map_HBE$AgeGrp <- ifelse(Map_HBE$Age_Rounded < 7, "5- and 6-year-olds", "7 and up")
  Map56 <- subset(Map_HBE, Map_HBE$AgeGrp =="5- and 6-year-olds")
  Map7up <- subset(Map_HBE, Map_HBE$AgeGrp =="7 and up")   
      
 ##GROUPED BAR PLOT##
      ##SOURCE: https://onunicornsandgenes.blog/2014/03/19/using-r-barplot-with-ggplot2/##
      ## 1. CREATE DF FOR AGE GRP 5 ##
      View(Map56)
      AgeGrp <- Map56$AgeGrp
      QW <- mean(Map56$Sum_Quantity.Word_Word.Quantity)
      NW <- mean(Map56$Sum_Numeral.Word_Word.Numeral)
      QN <- mean(Map56$Sum_Quantity.Numeral_Numeral.Quantity)
      age56 <- data.frame(AgeGrp, QW, NW,QN)
      age56.data <- melt(age56, id.vars='AgeGrp')
      View(age56.data)

      ## 2. CREATE DF FOR AGE GRP 6 > ##
      AgeGrp <- Map7up$AgeGrp
      QW <- mean(Map7up$Sum_Quantity.Word_Word.Quantity)
      NW <- mean(Map7up$Sum_Numeral.Word_Word.Numeral)
      QN <- mean(Map7up$Sum_Quantity.Numeral_Numeral.Quantity)
      age7 <- data.frame(AgeGrp, QW,NW,QN)
      age7.data <- melt(age7, id.vars='AgeGrp')
      View(age7.data)

      ## 3. MERGE 2 AGE GROUP DFS ##
      K <- merge(age56.data, age7.data, by=c("AgeGrp","variable","value"), all = T)
      names(K)[names(K) == "variable"] <- "Map"
      View(K)

      ## 4. CREATE NEW DATA FRAME WITH SEMS ##
          #AGE 5 and 6#         
          AgeGrp <- Map56$AgeGrp
          QW_SE <- std.error(Map56$Sum_Quantity.Word_Word.Quantity)
          NW_SE <- std.error(Map56$Sum_Numeral.Word_Word.Numeral)
          QN_SE <- std.error(Map56$Sum_Quantity.Numeral_Numeral.Quantity)
          SE_56 <- data.frame(AgeGrp, QW_SE, NW_SE, QN_SE)
          SE_56 <- melt(SE_56, id.vars='AgeGrp')
          View(SE_56)

         #AGE 7 and up#
         AgeGrp <- Map7up$AgeGrp
         QW_SE <- std.error(Map7up$Sum_Quantity.Word_Word.Quantity)
         NW_SE <- std.error(Map7up$Sum_Numeral.Word_Word.Numeral)
         QN_SE <- std.error(Map7up$Sum_Quantity.Numeral_Numeral.Quantity)
         SE_7 <- data.frame(AgeGrp, QW_SE, NW_SE, QN_SE)
         SE_7 <- melt(SE_7, id.vars='AgeGrp')
         View(SE_7)

      ## 5. MERGE 2 SEM DATA FRAMES & PREP TO MERGE WITH OTHER MERGED DF ##
      K2 <- merge(SE_56, SE_7, by=c("AgeGrp","variable","value"), all = T)
      View(K2)
      K2 <- data.frame(K2$AgeGrp, K2$value, K2$variable, K$Map)
      names(K2)[names(K2) == "K2.value"] <- "value"
      names(K2)[names(K2) == "K2.AgeGrp"] <- "AgeGrp"
      names(K2)[names(K2) == "K.Map"] <- "Map"
      names(K2)[names(K2) == "K2.variable"] <- "variable"
      View(K2)

      ## 6. MERGE PREVIOUSLY COMBINED DATAFRAME WITH SEM DATA FRAME ##
      BOOYAH <- merge(K, K2, by=c("AgeGrp","Map"), all = T)
      names(BOOYAH)[names(BOOYAH) == "value.x"] <- "mean"
      names(BOOYAH)[names(BOOYAH) == "value.y"] <- "sem"
      View(BOOYAH)

      ## 7. ADD COLUMNS FOR ERROR BARS ##
             lower <- BOOYAH$mean - BOOYAH$sem
             upper <- BOOYAH$mean + BOOYAH$sem
             BOOYAH<- cbind(BOOYAH, lower, upper)
             View(BOOYAH)

      ## 8. CREATE BAR PLOT ##
All_Bar <- ggplot(BOOYAH, aes(BOOYAH$Map, BOOYAH$mean)) + geom_bar(aes(fill = BOOYAH$AgeGrp), width = 0.6, position = position_dodge(width=0.7), stat="identity") + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds", "7 to 9-year-olds")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17), limits = c(0,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity and Numeral", "Quantity and Word", "Numeral and Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=12, family="Times New Roman"))
BARS <- All_Bar + geom_errorbar(aes(ymax=BOOYAH$upper, ymin=BOOYAH$lower, group=AgeGrp), width=.5, position=position_dodge(0.7), data=BOOYAH)
BARS

#TESTING SIGNIFICANCE BETWEEN BARS#
t.test(Map56$Sum_Quantity.Numeral_Numeral.Quantity, Map7up$Sum_Quantity.Numeral_Numeral.Quantity, paired = FALSE, alternative = "two.sided") 
t.test(Map56$Sum_Quantity.Word_Word.Quantity, Map7up$Sum_Quantity.Word_Word.Quantity, paired = FALSE, alternative = "two.sided")
t.test(Map56$Sum_Numeral.Word_Word.Numeral, Map7up$Sum_Numeral.Word_Word.Numeral, paired = FALSE, alternative = "two.sided") 

#BOX PLOT ONLY
 AgeGrp <- Map56$AgeGrp
 QW <- Map56$Sum_Quantity.Word_Word.Quantity
 NW <- Map56$Sum_Numeral.Word_Word.Numeral
 QN <- Map56$Sum_Quantity.Numeral_Numeral.Quantity
 age56 <- data.frame(AgeGrp, QW, NW,QN)
 age56.data <- melt(age56, id.vars='AgeGrp')
 View(age56.data)
 AgeGrp <- Map7up$AgeGrp
 QW <- Map7up$Sum_Quantity.Word_Word.Quantity
 NW <- Map7up$Sum_Numeral.Word_Word.Numeral
 QN <- Map7up$Sum_Quantity.Numeral_Numeral.Quantity
 age7 <- data.frame(AgeGrp, QW,NW,QN)
 age7.data <- melt(age7, id.vars='AgeGrp')
 View(age7.data)
 B <- merge(age56.data, age7.data, by=c("AgeGrp","variable","value"), all = T)
 names(B)[names(B) == "variable"] <- "Map"
 View(B)
All_BOX <- ggplot(B, aes(B$Map, B$value, fill=B$AgeGrp)) + geom_boxplot() + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds", "7 to 9-year-olds")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
All_BOX

#BOXPLOT AND VIOLIN#
dodge <- position_dodge(width = 0.5)
All_BV <- ggplot(B, aes(B$Map, B$value, fill=B$AgeGrp)) + geom_violin (position = dodge)+ geom_boxplot(width=0.2, position = dodge) + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds", "7 to 9-year-olds")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
All_BV


#ANOVA: Map Pair, Age Grp, Interaction
      #Creating Data Frame with Summed Scores, Map Pair, and Age Grp
      which(colnames(Map_HBE)=="Difference_Numeral.Word_Word.Numeral" #323
      HBE_AOV <- Map_HBE[, -c(1:323)] 
      View(HBE_AOV)
      HBE_AOV <- pivot_longer(data = HBE_AOV, cols=c(starts_with("Sum")), names_to = c("Type"), values_to = "Sum Correct Per Map Pair")
      View(HBE_AOV) 
      Map_Pair <- c()
      for(i in 1:141)
          Map_Pair[i] <- ifelse(grepl("Sum_Numeral.Word_Word.Numeral", HBE_AOV$Type[i]), "Numeral-Word", ifelse(grepl("Sum_Quantity.Numeral_Numeral.Quantity", HBE_AOV$Type[i]), "Quantity-Numeral", ifelse(grepl("Sum_Quantity.Word_Word.Quantity", HBE_AOV$Type[i]), "Quantity-Word", "bananas")))
      HBE_AOV <- cbind(HBE_AOV, Map_Pair)
      View(HBE_AOV)
      #Running the ANOVA
      aov <- aov(`Sum Correct Per Map Pair` ~ Map_Pair + AgeGrp + Map_Pair:AgeGrp, data = HBE_AOV)
      summary(aov) 
      TukeyHSD(aov)
 
     #Obtaining ETA-SQUARED
     #SOURCE: https://cran.r-project.org/web/packages/lsr/lsr.pdf
     install.packages("lsr")
     library(lsr)
     etaSquared(aov, type=2)

#Evaluating the interaction between age and map pairs
	#RAW NUMBER correct & PROPORTION correct & Significance from chance, TABLES
	Map56AvgCorr <- colMeans(subset(Map56, select = c(Sum_Quantity.Numeral_Numeral.Quantity, Sum_Quantity.Word_Word.Quantity, Sum_Numeral.Word_Word.Numeral)), na.rm = TRUE) 
	Map56AvgCorr
	Map56Means <- c((Map56AvgCorr[1]/17), (Map56AvgCorr[2]/17), (Map56AvgCorr[3]/17))
	Map56Means
	
	wilcox.test(Map56$Sum_Quantity.Numeral_Numeral.Quantity, mu = .25, alternative = "greater") 
	wilcox.test(Map56$Sum_Quantity.Word_Word.Quantity, mu = .25, alternative = "greater") 
	wilcox.test(Map56$Sum_Numeral.Word_Word.Numeral, mu = .25, alternative = "greater") 

	Map7upAvgCorr <- colMeans(subset(Map7up, select = c(Sum_Quantity.Numeral_Numeral.Quantity, Sum_Quantity.Word_Word.Quantity, Sum_Numeral.Word_Word.Numeral)), na.rm = TRUE) 
	Map7upAvgCorr
	Map7upMeans <- c((Map7upAvgCorr[1]/17), (Map7upAvgCorr[2]/17), (Map7upAvgCorr[3]/17))
	Map7upMeans

	wilcox.test(Map7up$Sum_Quantity.Numeral_Numeral.Quantity, mu = .25, alternative = "greater") 
	wilcox.test(Map7up$Sum_Quantity.Word_Word.Quantity, mu = .25, alternative = "greater") 
	wilcox.test(Map7up$Sum_Numeral.Word_Word.Numeral, mu = .25, alternative = "greater") 
	
	#Paired t-tests (same sample, different variables)
	     install.packages("effsize") #compute cohen's d
	     library(effsize)
     
        #Age Group comparisons WITHIN mapping pairs
	    #QN
	    t.test(Map56$Sum_Quantity.Numeral_Numeral.Quantity,Map7up$Sum_Quantity.Numeral_Numeral.Quantity, paired = FALSE, alternative = "two.sided") 
	    mean(Map56$Sum_Quantity.Numeral_Numeral.Quantity)
	    mean(Map7up$Sum_Quantity.Numeral_Numeral.Quantity) 
	    cohen.d(Map56$Sum_Quantity.Numeral_Numeral.Quantity,Map7up$Sum_Quantity.Numeral_Numeral.Quantity,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE) 
	    #QW
	    t.test(Map56$Sum_Quantity.Word_Word.Quantity,Map7up$Sum_Quantity.Word_Word.Quantity, paired = FALSE, alternative = "two.sided") 
	    mean(Map56$Sum_Quantity.Word_Word.Quantity) 
	    mean(Map7up$Sum_Quantity.Word_Word.Quantity) 
	    cohen.d(Map56$Sum_Quantity.Word_Word.Quantity,Map7up$Sum_Quantity.Word_Word.Quantity,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE) 
	    #NW
	    t.test(Map56$Sum_Numeral.Word_Word.Numeral, Map7up$Sum_Numeral.Word_Word.Numeral, paired = FALSE, alternative = "two.sided") 
	    mean(Map56$Sum_Numeral.Word_Word.Numeral) 
	    mean(Map7up$Sum_Numeral.Word_Word.Numeral) 
	    cohen.d(Map56$Sum_Numeral.Word_Word.Numeral, Map7up$Sum_Numeral.Word_Word.Numeral,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE) 
     
      #Age Group comparisons ACROSS mapping pairs
	  #QN vs NW
	      #5 and 6
	      t.test(Map56$Sum_Quantity.Numeral_Numeral.Quantity,Map56$Sum_Numeral.Word_Word.Numeral, paired = TRUE, alternative = "two.sided")
	      cohen.d(Map56$Sum_Quantity.Numeral_Numeral.Quantity,Map56$Sum_Numeral.Word_Word.Numeral, pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE)
	      #7 & up
	      t.test(Map7up$Sum_Quantity.Numeral_Numeral.Quantity,Map7up$Sum_Numeral.Word_Word.Numeral, paired = TRUE, alternative = "two.sided")
	      cohen.d(Map7up$Sum_Quantity.Numeral_Numeral.Quantity,Map7up$Sum_Numeral.Word_Word.Numeral,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE)

	    #QN vs QW
	       #5 and 6
	       t.test(Map56$Sum_Quantity.Numeral_Numeral.Quantity, Map56$Sum_Quantity.Word_Word.Quantity, paired = TRUE, alternative = "two.sided")
	       cohen.d(Map56$Sum_Quantity.Numeral_Numeral.Quantity, Map56$Sum_Quantity.Word_Word.Quantity,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE)
	       #7 & up
	       t.test(Map7up$Sum_Quantity.Numeral_Numeral.Quantity, Map7up$Sum_Quantity.Word_Word.Quantity, paired = TRUE, alternative = "two.sided")
	       cohen.d(Map7up$Sum_Quantity.Numeral_Numeral.Quantity, Map7up$Sum_Quantity.Word_Word.Quantity,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE)

	    #NW vs QW
	       #5 and 6
	       t.test(Map56$Sum_Numeral.Word_Word.Numeral, Map56$Sum_Quantity.Word_Word.Quantity, paired = TRUE, alternative = "two.sided")
	       cohen.d(Map56$Sum_Numeral.Word_Word.Numeral, Map56$Sum_Quantity.Word_Word.Quantity,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE)
	       #7 & up
	       t.test(Map7up$Sum_Numeral.Word_Word.Numeral, Map7up$Sum_Quantity.Word_Word.Quantity, paired = TRUE, alternative = "two.sided")
	       cohen.d(Map7up$Sum_Numeral.Word_Word.Numeral, Map7up$Sum_Quantity.Word_Word.Quantity,pooled=TRUE,paired=FALSE, na.rm=FALSE, hedges.correction=FALSE, conf.level=0.95,noncentral=FALSE)
       
#Analyzing Mapping Types, our spreadsheet was set up prior to determining mapping type nomenclature. The mapping type names in these codes are opposite to the mapping type in our paper, i.e. numeral_word in coding is really what we refer to as word-to-numeral.
	  # COMPARE each type to chance 
	  wilcox.test(Map_HBE$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") #p-value = 4.642e-10
	  wilcox.test(Map_HBE$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") #p-value = 5.379e-10
	  wilcox.test(Map_HBE$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") #p-value = 4.401e-10
	  wilcox.test(Map_HBE$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") #p-value = 8.511e-10
	  wilcox.test(Map_HBE$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") #p-value = 2.106e-10
	  wilcox.test(Map_HBE$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") #p-value = 3.737e-11
	  
	  #Scatterplots of Proportion Corrects for Mapping Types 
	  nq <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Quantity.Numeral)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Numeral-Quantity", title = "A") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
	  qn <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Numeral.Quantity)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Quantity-Numeral", title="B") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
	  wq <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Quantity.Word)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Word-Quantity", title = "C") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
	  qw <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Word.Quantity)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Quantity-Word", title = "D") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))    
	  wn <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Numeral.Word)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Word-Numeral", title = "E") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
	  nw <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Word.Numeral)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Numeral-Word", title = "F") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
	  grid.arrange(nq,wq,wn,qn,qw,nw,ncol = 3)

#Asymmetries?: Comparing mapping types within a pair (i.e., numeral-to-word vs word-to-numeral)
	#Group Comparisons
      QW<-wilcox.test(Map_HBE$SumTotal_QuantityWord, Map_HBE$SumTotal_WordQuantity, paired = TRUE, exact=FALSE)
      QW #V = 865.5, p-value = 1.427e-07
      QW_Zstat<-qnorm(QW$p.value/2)
      QW_Zstat
      abs(QW_Zstat)/sqrt(17) #calculates r value, 1.27615
      
      QN<-wilcox.test(Map_HBE$SumTotal_QuantityNumeral, Map_HBE$SumTotal_NumeralQuantity, paired = TRUE, exact=FALSE)
      QN #V = 799, p-value = 8.193e-07
      QN_Zstat<-qnorm(QN$p.value/2)
      QN_Zstat
      abs(QN_Zstat)/sqrt(17) #1.195876
      
      WN<-wilcox.test(Map_HBE$SumTotal_WordNumeral, Map_HBE$SumTotal_NumeralWord, paired = TRUE, exact=FALSE)
      WN #V = 0, p-value = 1.478e-09
      WN_Zstat<-qnorm(WN$p.value/2)
      WN_Zstat
      abs(WN_Zstat)/sqrt(17) #1.466557
 	
	#Individual Comparisons using difference scores
	shapiro.test(Map_HBE$Difference_Numeral.Word_Word.Numeral) #W = 0.58571, p-value = 2.706e-10
	shapiro.test(Map_HBE$Difference_Quantity.Numeral_Numeral.Quantity) #W = 0.83811, p-value = 1.276e-05
	shapiro.test(Map_HBE$Difference_Quantity.Word_Word.Quantity) #W = 0.91952, p-value = 0.003215

	#Are there still asymmetries for the youngest children (5-year-olds) & quantities 1-5 (comparing to Hurst et al. 2017)
	small <- mutate(Map_HBE, smWN= AvgCorrect_Sm_WN * AvgCorrect_Med_WN, smQN= AvgCorrect_Sm_QN * AvgCorrect_Med_QN, smQW= AvgCorrect_Sm_QW * AvgCorrect_Med_QW)
	View(small)
	small$AgeGrp <- ifelse(small$Age_Rounded < 6, "5-year-olds", "6 and up")
	sm_Map5 <- subset(small, small$AgeGrp =="5-year-olds")
	View(sm_Map5)
	Small_type <- mutate(Map_HBE, smNQ= AvgCorrect_Sm_QuantityNumeral * AvgCorrect_Med_QuantityNumeral, smQN= AvgCorrect_Sm_NumeralQuantity * AvgCorrect_Med_NumeralQuantity, smNW= AvgCorrect_Sm_WordNumeral * AvgCorrect_Med_WordNumeral, sm_WN= AvgCorrect_Sm_NumeralWord * AvgCorrect_Med_NumeralWord, sm_WQ= AvgCorrect_Sm_QuantityWord, AvgCorrect_Med_QuantityWord, sm_QW= AvgCorrect_Sm_WordQuantity, AvgCorrect_Med_WordQuantity)
	View(Small_type)
	Small_type$AgeGrp <- ifelse(Small_type$Age_Rounded < 6, "5 year-olds", "6 and up")
	sm_Map5_type <- subset(Small_type, Small_type$AgeGrp =="5 year-olds") 
	View(sm_Map5_type)
	
	sm_QN_5<-wilcox.test(sm_Map5_type$smQN, sm_Map5_type$smNQ, paired = TRUE, exact=FALSE)
	sm_QN_5 #V = 13, p-value = 0.9301
	sm_NW_5<-wilcox.test(sm_Map5_type$sm_WN, sm_Map5_type$smNW, paired = TRUE, exact=FALSE)
	sm_NW_5 #V = 5, p-value = 0.4142
	sm_QW_5<-wilcox.test(sm_Map5_type$sm_QW, sm_Map5_type$sm_WQ, paired = TRUE, exact=FALSE)
	sm_QW_5 #V = 0, p-value = 0.1736
		
#Set size comparisons by mapping pairs and age
	#Creating the DFs
	which(colnames(Map_HBE)=="AvgCorrect_Sm_QW") #312th column 
	which(colnames(Map_HBE)=="AvgCorrect_Lrg_WN") #320th column
	HBE_long2 <- pivot_longer(Map_HBE, cols = 312:320, values_to = "Pair_Size")
	View(HBE_long2)
	which(colnames(HBE_long2)=="Item1_QN_Answer") #21
	which(colnames(HBE_long2)=="Sum_Numeral.Word_Word.Numeral") #317
	HBE_short2 <- HBE_long2[,-c(21:317)]
	View(HBE_short2)
	#Add Set Size Columns
	HBE_short2 <-  mutate(HBE_short2, SetSize = case_when(grepl("Sm", HBE_short2$name) ~ "Small", grepl("Med", HBE_short2$name) ~"Medium", grepl("Lrg", HBE_short2$name) ~"Large"))
	HBE_short2$Set_Size <- as.factor(factor(as.character(HBE_short2$SetSize), levels=c("Small", "Medium", "Large"), exclude=""))
	HBE_short2$Set_Size_refM <- as.factor(factor(as.character(HBE_short2$SetSize), levels=c("Medium", "Small", "Large"), exclude=""))
	HBE_short2$Set_Size_refL <- as.factor(factor(as.character(HBE_short2$SetSize), levels=c("Large","Medium", "Small"), exclude=""))
	#Add Map Pair Columns
	HBE_short2 <- mutate(HBE_short2, MapPair = case_when(grepl("QW", HBE_short2$name) ~ "Quantity-Word", grepl("QN", HBE_short2$name) ~"Quantity-Numeral", grepl("WN", HBE_short2$name) ~"Numeral-Word"))
	HBE_short2$MapPair <- as.factor(factor(as.character(HBE_short2$MapPair), levels=c("Numeral-Word","Quantity-Numeral", "Quantity-Word"), exclude=""))
	HBE_short2$MapPair_refQN <- as.factor(factor(as.character(HBE_short2$MapPair), levels=c("Quantity-Numeral", "Quantity-Word","Numeral-Word"), exclude=""))
	HBE_short2$MapPair_refQW <- as.factor(factor(as.character(HBE_short2$MapPair), levels=c("Quantity-Word","Numeral-Word","Quantity-Numeral"), exclude=""))
	View(HBE_short2)
	
	HBE_short2$AgeGrp <- ifelse(HBE_short2$Age_Rounded < 6, "5-year-olds", "6-year-olds")
	Map5 <- subset(HBE_short2, HBE_short2$AgeGrp == "5-year-olds")
	Map6 <- subset(HBE_short2, HBE_short2$AgeGrp == "6-year-olds")
	#Create 2 DFs for 5 and 6-year-olds and 7 to 9-year-olds
	HBE_short2$AgeGrp_5v7 <- ifelse(HBE_short2$Age_Rounded < 7, "5 and 6-year-olds", "7 to 9-year-olds")
	View(HBE_short2)
	HBE_short2_5 <- subset(HBE_short2, AgeGrp_5v7 == "5 and 6-year-olds")
	View(HBE_short2_5)
	HBE_short2_7 <- subset(HBE_short2, AgeGrp_5v7 == "7 to 9-year-olds")
	View(HBE_short2_7) 
	
	qw_5 <- subset (HBE_short2_5, HBE_short2_5$MapPair == "Quantity-Word")
	View(qw_5)
	qn_5 <- subset (HBE_short2_5, HBE_short2_5$MapPair == "Quantity-Numeral")
	View(qn_5)
	nw_5 <- subset (HBE_short2_5, HBE_short2_5$MapPair == "Numeral-Word")
	View(nw_5)

	qn_5_only <- subset (qn_5, qn_5$Age_Rounded < 6)
	View(qn_5_only)
	qn_6_only <- subset (qn_5, qn_5$Age_Rounded >=6)
	View(qn_6_only)
	qw_5_only <- subset (qw_5, qw_5$Age_Rounded < 6)
	View(qw_5_only)
	qw_6_only <- subset (qw_5, qw_5$Age_Rounded >=6)
	View(qw_6_only)
	nw_5_only <- subset (nw_5, nw_5$Age_Rounded < 6)
	View(nw_5_only)
	nw_6_only <- subset (nw_5, nw_5$Age_Rounded >=6)
	View(nw_6_only)

	#Boxplot of 2 age groups & 3 mapping pairs (proportion correct)
	MapPair <- HBE_short2$MapPair
	Prop <- HBE_short2$Pair_Size
	AgeGrp <- HBE_short2$AgeGrp
	dodge <- position_dodge(width = 0.5)
	ALL_B <- ggplot(HBE_short2, aes(MapPair, Prop, fill=AgeGrp)) + geom_boxplot(width=0.2, position = dodge) + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5 and 6-year-olds (n=25)", "7 to 9-year-olds (n=22)")) + labs( y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Quantity-Numeral","Quantity-Word","Numeral-Word"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	ALL_B
#BOX PLOTS Prop Correct for 7-9 year olds by set size#
	qw_7 <- subset (HBE_short2_7, HBE_short2_7$MapPair == "Quantity-Word")
	View(qw_7)
	qn_7 <- subset (HBE_short2_7, HBE_short2_7$MapPair == "Quantity-Numeral")
	View(qn_7)
	nw_7 <- subset (HBE_short2_7, HBE_short2_7$MapPair == "Numeral-Word")
	View(nw_7)
	dodge <- position_dodge(width = 0.5)
	qn_7_b <- ggplot(qn_7, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + ggtitle("Quantity-Numeral") + labs( y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_text(hjust = 0.5),axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	qn_7_b
	qw_7_b <- ggplot(qw_7, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + ggtitle("Quantity-Word") + labs( y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_text(hjust = 0.5),axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	qw_7_b
	nw_7_b <- ggplot(nw_7, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + ggtitle("Numeral-Word") + labs( y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_text(hjust = 0.5),axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	nw_7_b
	grid.arrange(qn_7_b,qw_7_b,nw_7_b,ncol = 3)
	
#5 vs 6 year olds
	#Boxplot 5 vs 6 year olds, map pairs, proportion correct
	dodge <- position_dodge(width = 0.5)
	ALL_56 <- ggplot(HBE_short2_5, aes(MapPair, Pair_Size, fill=AgeGrp)) + geom_boxplot(width=0.2, position = dodge) + scale_fill_manual(values=c("grey87", "grey51"), labels = c("5-year-olds (n=15)", "6-year-olds (n=10)")) + labs( y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Quantity-Numeral","Quantity-Word","Numeral-Word"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	ALL_56

	#Boxplots by Map Pairs & Set Sizes#
	library(grid)
	dodge <- position_dodge(width = 0.5)
	qn_5_only <- subset (qn_5, qn_5$Age_Rounded < 6)
	qn_6_only <- subset (qn_5, qn_5$Age_Rounded >=6)
	qn_5_only_box <- ggplot(qn_5_only, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + labs(x="Quantity-Numeral", y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	qn_5_only_box
	qn_6_only_box <- ggplot(qn_6_only, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + labs(x="Quantity-Numeral", y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	qn_6_only_box
	qw_5_only <- subset (qw_5, qw_5$Age_Rounded < 6)
	View(qw_5_only)
	qw_6_only <- subset (qw_5, qw_5$Age_Rounded >=6)
	View(qw_6_only)
	qw_5_only_box <- ggplot(qw_5_only, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + labs(x="Quantity-Word", y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	qw_5_only_box
	qw_6_only_box <- ggplot(qw_6_only, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + labs(x="Quantity-Word", y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	qw_6_only_box
	nw_5_only <- subset (nw_5, nw_5$Age_Rounded < 6)
	nw_6_only <- subset (nw_5, nw_5$Age_Rounded >=6)
	nw_5_only_box <- ggplot(nw_5_only, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + labs(x="Numeral-Word", y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	nw_5_only_box
	nw_6_only_box <- ggplot(nw_6_only, aes(Set_Size,Pair_Size)) + geom_boxplot(width=0.2, position = dodge) + labs(x="Numeral-Word", y="Proportion Correct") + scale_y_continuous (breaks=c(0.0, 0.2, 0.4,0.6,0.8,1.0), limits = c(0,1), expand = c(0,0)) + scale_x_discrete(limits=c("Small","Medium","Large"), expand = c(.2,0),labels = c("Small", "Medium", "Large")) + theme_bw() + theme(legend.position="top", plot.title=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=16, family="Times New Roman")) 
	nw_6_only_box
	yo_5 <- grid.arrange(qn_5_only_box,qw_5_only_box,nw_5_only_box, ncol = 3, top=textGrob("5-year-olds (n=15)", gp=gpar(fontsize=16,fontface = "bold",fontfamily="Times")))
	yo_6 <- grid.arrange(qn_6_only_box,qw_6_only_box,nw_6_only_box, ncol = 3, top=textGrob("6-year-olds (n=10)", gp=gpar(fontsize=16,fontface = "bold",fontfamily="Times")))
	grid.arrange(yo_5,yo_6,ncol=1)

#Means for Set Sizes across map pairs & 2 age groups
	Map56 <- subset(Map_HBE, Map_HBE$Age_Rounded < 7)
	Map79 <- subset(Map_HBE, Map_HBE$Age_Rounded >= 7)
	View(Map56)
	View(Map79)
	
	mean(Map56$AvgCorrect_Sm_QW) #0.9432
	mean(Map56$AvgCorrect_Med_QW) #0.78
	mean(Map56$AvgCorrect_Lrg_QW) #0.7424
	mean(Map56$AvgCorrect_Sm_QN) #0.9632
	mean(Map56$AvgCorrect_Med_QN) #0.85
	mean(Map56$AvgCorrect_Lrg_QN) #0.7768
	mean(Map56$AvgCorrect_Sm_WN) #0.9632
	mean(Map56$AvgCorrect_Med_WN) #0.99
	mean(Map56$AvgCorrect_Lrg_WN) #0.9416
	
	mean(Map79$AvgCorrect_Sm_QW) #0.9772727
	mean(Map79$AvgCorrect_Med_QW) #0.9431818
	mean(Map79$AvgCorrect_Lrg_QW) #0.9331818
	mean(Map79$AvgCorrect_Sm_QN) #0.9922727
	mean(Map79$AvgCorrect_Med_QN) #0.9886364
	mean(Map79$AvgCorrect_Lrg_QN) #0.9613636
	mean(Map79$AvgCorrect_Sm_WN) #0.9886364
	mean(Map79$AvgCorrect_Med_WN) #0.9659091
	mean(Map79$AvgCorrect_Lrg_WN) #0.9718182

	#Significantly above chance?
	wilcox.test(Map56$AvgCorrect_Sm_QW, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 1.66e-06
	wilcox.test(Map56$AvgCorrect_Med_QW, mu = .25, alternative = "greater") #p-value = V = 273.5, p-value = 1.296e-05
	wilcox.test(Map56$AvgCorrect_Lrg_QW, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 5.945e-06
	wilcox.test(Map56$AvgCorrect_Sm_QN, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 9.825e-07
	wilcox.test(Map56$AvgCorrect_Med_QN, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 3.995e-06
	wilcox.test(Map56$AvgCorrect_Lrg_QN, mu = .25, alternative = "greater") #p-value =  V = 325, p-value = 5.794e-06
	wilcox.test(Map56$AvgCorrect_Sm_WN, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 1.303e-06
	wilcox.test(Map56$AvgCorrect_Med_WN, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 4.831e-07
	wilcox.test(Map56$AvgCorrect_Lrg_WN, mu = .25, alternative = "greater") #p-value = V = 325, p-value = 3.528e-06

	wilcox.test(Map79$AvgCorrect_Sm_QW, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 3.324e-06
	wilcox.test(Map79$AvgCorrect_Med_QW, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 5.904e-06
	wilcox.test(Map79$AvgCorrect_Lrg_QW, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 1.312e-05
	wilcox.test(Map79$AvgCorrect_Sm_QN, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 2.305e-06
	wilcox.test(Map79$AvgCorrect_Med_QN, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 2.305e-06
	wilcox.test(Map79$AvgCorrect_Lrg_QN, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 8.796e-06
	wilcox.test(Map79$AvgCorrect_Sm_WN, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 2.305e-06
	wilcox.test(Map79$AvgCorrect_Med_WN, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 3.329e-06
	wilcox.test(Map79$AvgCorrect_Lrg_WN, mu = .25, alternative = "greater") #p-value = V = 253, p-value = 3.329e-06 
	
#Tobit Models, resource: https://stats.idre.ucla.edu/r/dae/tobit-models/
	HBE_long2$AgeGrp <- ifelse(Map_HBE$Age_Rounded < 7, "5-6", "7-9")
	HBE_long2 <-  mutate(HBE_long2, SetSize = case_when(grepl("Sm", HBE_long2$name) ~ "Small", grepl("Med", HBE_long2$name) ~"Medium", grepl("Lrg", HBE_long2$name) ~"Large"))
	HBE_long2$Set_Size <- as.factor(factor(as.character(HBE_long2$SetSize), levels=c("Small", "Medium", "Large"), exclude=""))
	HBE_long2 <- mutate(HBE_long2, MapPair = case_when(grepl("QW", HBE_long2$name) ~ "Quantity-Word", grepl("QN", HBE_long2$name) ~"Quantity-Numeral", grepl("WN", HBE_long2$name) ~"Numeral-Word"))
	HBE_long2$MapPair <- as.factor(factor(as.character(HBE_long2$MapPair), levels=c("Numeral-Word","Quantity-Numeral", "Quantity-Word"), exclude=""))
	View(HBE_long2)
	#5-6 vs 7-9 YO model below produced Hauck-Donner effects
	summary(agegrps <- vglm(HBE_long2$Pair_Size ~ HBE_long2$Set_Size + HBE_long2$MapPair + HBE_long2$Age_Rounded, tobit(Lower=0, Upper = 1), data = HBE_long2))
	#5 vs 6 year olds
	summary(agegrp56 <- vglm(HBE_short2_5$Pair_Size ~ HBE_short2_5$Set_Size + HBE_short2_5$MapPair + HBE_short2_5$AgeGrp, tobit(Lower=0, Upper = 1), data = HBE_short2_5))
	#6-year-olds only
	Map6 <- subset(HBE_short2_5, HBE_short2_5$AgeGrp == "6-year-olds")
	View(Map6)
	summary(Map6_t <- vglm(Pair_Size ~ Set_Size + MapPair, tobit(Upper = 1), data = Map6))
	summary(Map6_t_ref <- vglm(Pair_Size ~ Set_Size_refM + MapPair, tobit(Upper = 1), data = Map6))
	#Checking model fit for 6 yo 
	Map6$yhat <- fitted(Map6_t)[,1]
	Map6$rr <- resid(Map6_t, type = "response")
	Map6$rp <- resid(Map6_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(Map6, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(Map6, cor(yhat, Pair_Size)) #0.3629535
	r 
	r^2 #0.3629535
	#Looking at Map Pairs	
	summary(nw6_t <- vglm(nw_6_only$Pair_Size ~ nw_6_only$Set_Size, tobit(Lower=0, Upper = 1), data = nw_6_only)) 
	#Numeral-Word does not run b/c AT CEILING
	summary(qn6_t <- vglm(qn_6_only$Pair_Size ~ qn_6_only$Set_Size, tobit(Lower=0, Upper = 1), data = qn_6_only))
	summary(qn6_t_ref <- vglm(qn_6_only$Pair_Size ~ qn_6_only$Set_Size_refM + qn_6_only$Age_Rounded, tobit(Lower=0, Upper = 1), data = qn_6_only))
	#Checking model fit for 6 yo QN
	qn_6_only$yhat <- fitted(qn6_t)[,1]
	qn_6_only$rr <- resid(qn6_t, type = "response")
	qn_6_only$rp <- resid(qn6_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(qn_6_only, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(qn_6_only, cor(yhat, Pair_Size)) #0.3706062
	r 
	r^2 #0.1373489
	summary(qw6_t <- vglm(qw_6_only$Pair_Size ~ qw_6_only$Set_Size + qw_6_only$Age_Rounded, tobit(Lower=0, Upper = 1), data = qw_6_only))
	summary(qw6_t_ref <- vglm(qw_6_only$Pair_Size ~ qw_6_only$Set_Size_refM + qw_6_only$Age_Rounded, tobit(Lower=0, Upper = 1), data = qw_6_only))
	#Checking model fit for 6 YO QW
	qw_6_only$yhat <- fitted(qw6_t)[,1]
	qw_6_only$rr <- resid(qw6_t, type = "response")
	qw_6_only$rp <- resid(qw6_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(qw_6_only, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(qw_6_only, cor(yhat, Pair_Size)) #0.3188118
	r 
	r^2 #0.1016409
	
	#5-year-olds only
	summary(Map5_t <- vglm(Pair_Size ~ Set_Size + MapPair, tobit(Upper = 1), data = Map5))
	summary(Map5_t_ref <- vglm(Pair_Size ~ Set_Size_refM + MapPair, tobit(Upper = 1), data = Map5))
	#Checking model fit for 5 yo 
	Map5$yhat <- fitted(Map5_t)[,1]
	Map5$rr <- resid(Map5_t, type = "response")
	Map5$rp <- resid(Map5_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(Map5, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(Map5, cor(yhat, Pair_Size)) #0.5339397
	r 
	r^2 #0.2850916
	#Looking at Map Pairs
	summary(nw5_t <- vglm(nw_5_only$Pair_Size ~ nw_5_only$Set_Size, tobit(Lower=0, Upper = 1), data = nw_5_only)) 
	summary(nw5_t_ref <- vglm(nw_5_only$Pair_Size ~ nw_5_only$Set_Size_refM, tobit(Lower=0, Upper = 1), data = nw_5_only)) 
	#Checking model fit for 5 yo NW
	nw_5_only$yhat <- fitted(nw5_t)[,1]
	nw_5_only$rr <- resid(nw5_t, type = "response")
	nw_5_only$rp <- resid(nw5_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(nw_5_only, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(nw_5_only, cor(yhat, Pair_Size)) #0.3517367
	r 
	r^2 #0.1237187
	summary(qn5_t <- vglm(qn_5_only$Pair_Size ~ qn_5_only$Set_Size, tobit(Lower=0, Upper = 1), data = qn_5_only))
	summary(qn5_t_ref <- vglm(qn_5_only$Pair_Size ~ qn_5_only$Set_Size_refM + qn_5_only$Age_Rounded, tobit(Lower=0, Upper = 1), data = qn_5_only))
	#Checking model fit for 5 yo QN
	qn_5_only$yhat <- fitted(qn5_t)[,1]
	qn_5_only$rr <- resid(qn5_t, type = "response")
	qn_5_only$rp <- resid(qn5_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(qn_5_only, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(qn_5_only, cor(yhat, Pair_Size)) #0.54546
	r 
	r^2 #0.2975266
	summary(qw5_t <- vglm(qw_5_only$Pair_Size ~ qw_5_only$Set_Size + qw_5_only$Age_Rounded, tobit(Lower=0, Upper = 1), data = qw_5_only))
	summary(qw5_t_ref <- vglm(qw_5_only$Pair_Size ~ qw_5_only$Set_Size_refM + qw_5_only$Age_Rounded, tobit(Lower=0, Upper = 1), data = qw_5_only))
	#Checking model fit for 5 yo QW
	qw_5_only$yhat <- fitted(qw5_t)[,1]
	qw_5_only$rr <- resid(qw5_t, type = "response")
	qw_5_only$rp <- resid(qw5_t, type = "pearson")[,1]
	par(mfcol = c(2, 3))
	with(qw_5_only, {
	    plot(yhat, rr, main = "Fitted vs Residuals")
	    qqnorm(rr)
	    plot(yhat, rp, main = "Fitted vs Pearson Residuals")
	    qqnorm(rp)
	    plot(Pair_Size, rp, main = "Actual vs Pearson Residuals")
	    plot(Pair_Size, yhat, main = "Actual vs Fitted")
	})
	r <- with(qw_5_only, cor(yhat, Pair_Size)) #0.4718548
	r 
	r^2 #0.2226469



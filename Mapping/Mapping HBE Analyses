#Mapping Analyses, following Hurst Analyses


##If any of the following not already imported need import.packages("[packagename]")

install.packages("tidyverse") # includes ggplot2??
install.packages("ggplot2") # for general plots
install.packages("beeswarm") # for beeswarm plots
install.packages("colorspace") # for fixing colors in plots
install.packages("stargazer") # for pretty regression output tables
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages("sure") # package for calculating residuals for ordinal logistic regression (https://journal.r-project.org/archive/2018/RJ-2018-004/RJ-2018-004.pdf)
install.packages("mediation") # package for testing mediation effects
install.packages("gridExtra")


library(tidyverse) 
library(ggplot2)
library(beeswarm)
library(colorspace) 
library(stargazer)
library(MASS)
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(sure) 
library(mediation) 
library(gridExtra)


setwd("/Users/labuser/Documents/R")
getwd()

#LAPTOP setwd("~/Desktop")

Mapping <- read.csv("Mapping_Coding_CH_190809.csv", na.strings = "N/A")
 
typeof(Mapping) # when importing using read.csv, resulting obj type is a list (data frame)
View(Mapping)

####HEARING KIDS ONLY####

Map_HBE <- subset(Mapping, Mapping$Including.in.Study == 'Yes' & Mapping$Coded. == "Yes" & Mapping$Group_2cat == 'Hearing')
View(Map_HBE)
str(Map_HBE)

#Q1: What does mapping performance look like with this age range (5-9)?
  
  #Proportion Correct for each Mapping Type (all HBE kids)
  qn <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Quantity.Numeral)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Quantity-Numeral") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1.1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  nq <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Numeral.Quantity)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Numeral-Quantity") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1.1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))

  wn <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Word.Numeral)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Word-Numeral") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1.1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  nw <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Numeral.Word)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Numeral-Word") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1.1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))

  qw <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Quantity.Word)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Quantity-Word") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1.1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  wq <- ggplot(Map_HBE, aes(x=Map_HBE$Age_Rounded, y=Map_HBE$AvgCorrect_Word.Quantity)) + geom_point() + geom_smooth(method="loess", se = FALSE) + labs(x="Age (Years)", y="Word-Quantity") + theme(text = element_text(size=11)) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1.1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))
  
  grid.arrange(qw,nw,qn,wq,wn,nq, ncol = 3)


# COMPARE each type to chance - Hurst et al used one-sample Wilcoxon Signed Rank tests (use median and assume roughly normal distribution around MEDIAN)
  wilcox.test(Map_HBE$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
  wilcox.test(Map_HBE$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
  wilcox.test(Map_sub$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
  wilcox.test(Map_HBE$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
  wilcox.test(Map_HBE$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
  wilcox.test(Map_HBE$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 


# ASYMMETRY?- Wilcoxon signed rank test with continuity correction
   #Quantity numeral better than numeral quantity?
   wilcox.test(Map_HBE$SumTotal_QuantityNumeral, Map_HBE$SumTotal_NumeralQuantity, paired=TRUE)
   #Quantity word better than word quantity?
   wilcox.test(Map_HBE$SumTotal_QuantityWord, Map_HBE$SumTotal_WordQuantity, paired=TRUE)
   #Numeral word better than word numeral?
   wilcox.test(Map_HBE$SumTotal_NumeralWord, Map_HBE$SumTotal_WordNumeral, paired=TRUE)
   

# get average RAW NUMBER correct for each mapping type across all kids 
MapAvgCorr <- colMeans(subset(Map_HBE, select = c(SumTotal_QuantityNumeral, SumTotal_NumeralQuantity, SumTotal_QuantityWord, SumTotal_WordQuantity, SumTotal_NumeralWord, SumTotal_WordNumeral)), na.rm = TRUE)
MapAvgCorr

# Mapping types are out of different numbers, so to calculate proportion correct need code below
MapMeans <- c((MapAvgCorr[1]/9), (MapAvgCorr[2]/8), (MapAvgCorr[3]/9), (MapAvgCorr[4]/8), (MapAvgCorr[5]/9), (MapAvgCorr[6]/8))
MapMeans


## 5 YO vs 6YOs and up ##

#create a column for age group
Map_HBE$AgeGrp <- ifelse(Map_HBE$Age_Rounded < 6, "5-year-olds", "6 and up")

Map5 <- subset(Map_HBE, Map_HBE$AgeGrp =="5-year-olds")
Map6up <- subset(Map_HBE, Map_HBE$AgeGrp =="6 and up")

#RAW NUMBER correct & PROPORTION correct
Map5AvgCorr <- colMeans(subset(Map5, select = c(SumTotal_QuantityNumeral, SumTotal_NumeralQuantity, SumTotal_QuantityWord, SumTotal_WordQuantity, SumTotal_NumeralWord, SumTotal_WordNumeral)), na.rm = TRUE) 
Map5AvgCorr
Map5Means <- c((Map5AvgCorr[1]/9), (Map5AvgCorr[2]/8), (Map5AvgCorr[3]/9), (Map5AvgCorr[4]/8), (Map5AvgCorr[5]/9), (Map5AvgCorr[6]/8))
Map5Means

Map6upAvgCorr <- colMeans(subset(Map6up, select = c(SumTotal_QuantityNumeral, SumTotal_NumeralQuantity, SumTotal_QuantityWord, SumTotal_WordQuantity, SumTotal_NumeralWord, SumTotal_WordNumeral)), na.rm = TRUE) 
Map6upAvgCorr
Map6Means <- c((Map6upAvgCorr[1]/9), (Map6upAvgCorr[2]/8), (Map6upAvgCorr[3]/9), (Map6upAvgCorr[4]/8), (Map6upAvgCorr[5]/9), (Map6upAvgCorr[6]/8))
Map6Means

#ALL SIGNIFICANTLY DIFFERENT FROM CHANCE?
# 5 YO 
wilcox.test(Map5$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map5$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map5$SumTotal_QuantityNumeral, Map5$SumTotal_NumeralQuantity, paired=TRUE) # ASYMMETRY for 5yos? 
#YES

wilcox.test(Map5$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map5$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map5$SumTotal_QuantityWord, Map5$SumTotal_WordQuantity, paired=TRUE) # ASYMMETRY? Quantity word better than word quantity?
#YES

wilcox.test(Map5$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map5$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map5$SumTotal_NumeralWord, Map5$SumTotal_WordNumeral, paired=TRUE) # ASYMMETRY?  Numeral word better than word numeral?
#MARGINAL (p=.054)

# 6 YO & >

wilcox.test(Map6up$AvgCorrect_Quantity.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map6up$AvgCorrect_Numeral.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map6up$SumTotal_QuantityNumeral, Map6up$SumTotal_NumeralQuantity, paired=TRUE) # ASYMMETRY for 5yos?
#YES

wilcox.test(Map6up$AvgCorrect_Quantity.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map6up$AvgCorrect_Word.Quantity, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map6up$SumTotal_QuantityWord, Map6up$SumTotal_WordQuantity, paired=TRUE) # ASYMMETRY? Quantity word better than word quantity?
#YES

wilcox.test(Map6up$AvgCorrect_Word.Numeral, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map6up$AvgCorrect_Numeral.Word, mu = .25, alternative = "greater") # is median numeral correct significantly greater than chance (0.25) 
wilcox.test(Map6up$SumTotal_NumeralWord, Map6up$SumTotal_WordNumeral, paired=TRUE) # ASYMMETRY?  Numeral word better than word numeral?
#YES



## SEPARATE INTO SMALL (1-3), MEDIUM (4-5), LARGE (6-9) QUANTITIES BY AGE, OVERALL NOT SEPARATED BY MAPPINGS ##
     #SMALL:
          #Target 1: Items 1, 10, 18, 35, 44
          #Target 2: Items 2, 19, 27, 36
          #Target 3: Items 6, 15, 26, 29, 41, 47
     #MEDIUM:
          #Target 4: Items 5, 11, 21, 32, 39, 51
          #Target 5: Items 8, 12, 23, 34, 37, 50
     #LARGE:
          #Target 6: Items 3, 16, 24, 31, 43, 49
          #Target 7: Items 9, 14, 22, 30, 38, 46
          #Target 8: Items 7, 17, 25, 28, 40, 48
          #Target 9: Items 4, 13, 20, 33, 42, 45

     # AGES 5 #
     Map5_Sm_AvgCorr <- colMeans(subset(Map5, select = c(Item1_Correct.,Item10_Correct.,Item18_Correct.,Item35_Correct., Item44_Correct.,Item2_Correct.,Item19_Correct.,Item27_Correct.,Item36_Correct.,Item6_Correct.,Item15_Correct.,Item26_Correct.,Item29_Correct.,Item41_Correct.,Item47_Correct.)), na.rm = TRUE) 
     wilcox.test(Map5_Sm_AvgCorr, mu = .25, alternative = "greater") #is mean of small quantities correct for ages 5 significantly greater than chance (0.25) 

     Map5_Med_AvgCorr <- colMeans(subset(Map5, select = c(Item5_Correct.,Item11_Correct.,Item21_Correct.,Item32_Correct., Item39_Correct.,Item51_Correct.,Item8_Correct.,Item12_Correct.,Item23_Correct.,Item34_Correct.,Item37_Correct.,Item50_Correct.)), na.rm = TRUE) 
     wilcox.test(Map5_Med_AvgCorr, mu = .25, alternative = "greater") #is mean of medium quantities correct for ages 5 significantly greater than chance (0.25) 

     Map5_Lrg_AvgCorr <- colMeans(subset(Map5, select = c(Item3_Correct.,Item16_Correct.,Item24_Correct.,Item31_Correct., Item43_Correct.,Item49_Correct.,Item9_Correct.,Item14_Correct.,Item22_Correct.,Item30_Correct.,Item38_Correct.,Item46_Correct., Item46_Correct., Item7_Correct., Item17_Correct., Item25_Correct.,Item28_Correct., Item40_Correct., Item48_Correct.,Item4_Correct.,Item13_Correct.,Item20_Correct.,Item33_Correct.,Item42_Correct.,Item45_Correct.)), na.rm = TRUE) 
     wilcox.test(Map5_Lrg_AvgCorr, mu = .25, alternative = "greater") #is mean of large quantities correct for ages 5 significantly greater than chance (0.25) 

     # AGES 6 & > #
     Map6up_Sm_AvgCorr <- colMeans(subset(Map6up, select = c(Item1_Correct.,Item10_Correct.,Item18_Correct.,Item35_Correct., Item44_Correct.,Item2_Correct.,Item19_Correct.,Item27_Correct.,Item36_Correct.,Item6_Correct.,Item15_Correct.,Item26_Correct.,Item29_Correct.,Item41_Correct.,Item47_Correct.)), na.rm = TRUE) 
     wilcox.test(Map6up_Sm_AvgCorr, mu = .25, alternative = "greater") #is mean of small quantities correct for ages 6 and > significantly greater than chance (0.25) 

     Map6up_Med_AvgCorr <- colMeans(subset(Map6up, select = c(Item5_Correct.,Item11_Correct.,Item21_Correct.,Item32_Correct., Item39_Correct.,Item51_Correct.,Item8_Correct.,Item12_Correct.,Item23_Correct.,Item34_Correct.,Item37_Correct.,Item50_Correct.)), na.rm = TRUE) 
     wilcox.test(Map6up_Med_AvgCorr, mu = .25, alternative = "greater") #is mean of medium quantities correct for ages 6 and > significantly greater than chance (0.25) 
     
     Map6up_Lrg_AvgCorr <- colMeans(subset(Map6up, select = c(Item3_Correct.,Item16_Correct.,Item24_Correct.,Item31_Correct., Item43_Correct.,Item49_Correct.,Item9_Correct.,Item14_Correct.,Item22_Correct.,Item30_Correct.,Item38_Correct.,Item46_Correct., Item46_Correct., Item7_Correct., Item17_Correct., Item25_Correct.,Item28_Correct., Item40_Correct., Item48_Correct.,Item4_Correct.,Item13_Correct.,Item20_Correct.,Item33_Correct.,Item42_Correct.,Item45_Correct.)), na.rm = TRUE) 
     wilcox.test(Map6up_Lrg_AvgCorr, mu = .25, alternative = "greater") #is mean of large quantities correct for ages 5 significantly greater than chance (0.25) 


## SEPARATE INTO SMALL (1-3), MEDIUM (4-5), LARGE (6-9) QUANTITIES BY AGE, SEPARATED BY MAPPING PAIRS ##


#1. Install and Load Libraries 

install.packages("car")
install.packages("sm")
install.packages("ggplot2") # for general plots
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages ("olsrr") #for testing normality
install.packages("ggpubr") #for density plots

library(ggplot2) 
library(MASS) 
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(olsrr)
library(car)
library(sm)
library(ggpubr)


#2. Check and Set Working Directory
      setwd("~/Desktop")
      getwd()      
      
#3. Import Data [[make sure is most recent version and saved as csv]]
      Map <- read.csv("Mapping_Coding_KW_200327.csv", na.strings = "N/A")
      #224 kids
      View(Map)   

## BASIC DEMOGRAPHICS ## 
      Map_Demo <- subset(Map, Map$Age_Rounded>=5 & Map$Age_Rounded<=10 | is.na(Map$Age_Rounded))
      View(Map_Demo) # 215 kids ages 5-9
      #we lose 9 kids from current age restriction. 5 kids < 5 (4 are DLE & 1 HBE, will include all if change to 4.5-9). 4 kids > 9 (should not include). 

#FOR DEMOGRAPHICS OF ALL POSSIBLE KIDS INCLUDING FOR MAPPING (*for paper will add: Map Include = Yes & Coded = Yes*)
      Total_Inc_Study <- subset(Map_Demo, Map_Demo$Including.in.Study == "Yes")
      View(Total_Inc_Study)
      # 197 total kids included in study  
      
      ## Included OVERALL: Numbers of Kids Per Group ##
      EE_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Early")
      View(EE_Inc)
      # 47 of 197 kids included are EE
      EL_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Later")
      View(EL_Inc)
      # 43 of 197 kids included are EL
      AE_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "ASL Early")
      View(AE_Inc)
      # 52 of 197 kids included are AE
      AL_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "ASL Later")
      View(AL_Inc)
      # 55 of 197 kids included are AL
      
      Total_Not_Inc_Study <- subset(Map_Demo, Map_Demo$Including.in.Study == "No")
      nrow(Total_Not_Inc_Study)
      View(Total_Not_Inc_Study)
      # 18 total kids not included in study
                     
      Total_NotTested_NA <- subset(Map_Demo,  Map_Demo$Tested == "No" | Map_Demo$Tested == "Not Yet" | is.na(Map_Demo$Including.in.Study))
      View(Total_NotTested_NA)
      # 15 Not Tested 
      
      Tested_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Tested == "Yes")
      View(Tested_Not_Inc)
      # 3 kid out of 17 not included in study were tested, NEED TO EXPLAIN WHY NOT INCLUDING! All had additional disabilities/suspected disabilities

      ## Tested But Not Included: How many from each group? ## 
            EE_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "English Early")
            nrow(EE_Not_Inc)
            # 0 of 3 kids tested but not included are EE
            EL_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "English Later")
            nrow(EL_Not_Inc)
            # 0 of 3 kids tested but not included are EL
            AE_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "ASL Early")
            nrow(AE_Not_Inc)
            # 1 of 3 kids tested but not included are AE
            AL_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "ASL Later")
            nrow(AL_Not_Inc)
            # 2 of 3 kids tested but not included are AL
   
      NotTested_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Tested == "No")
      nrow(NotTested_Not_Inc)
      #14 remaining kids listed as not included were not tested


## Creating a Table/"Matrix": Included vs Not (& not tested) by Group ##

      rnames <- c("Including in Study","Not Including in Study")
      cnames <- c("English Early","English Later","ASL Early","ASL Later")
      Table_IncStudy <- matrix(c(nrow(EE_Inc),nrow(EL_Inc),nrow(AE_Inc),nrow(AL_Inc),nrow(EE_Not_Inc),nrow(EL_Not_Inc),nrow(AE_Not_Inc),nrow(AL_Not_Inc)), nrow=2, ncol=4, byrow=TRUE, dimnames=list(rnames,cnames))
      Table_IncStudy

## Chi-Square on Table/"Matrix": Does the status of including in study depend on which group kids were in?, aka DNS more likely to not be included? ##
chisq.test(Table_IncStudy)
# Test statistic is p-value = 0.39, do not reject null, conclude that status of inclusion in study is not dependent on group 4 category. GOOD!

# Find observations with missing Age and SES values
      sum(is.na(Total_Inc_Study$Age_Rounded) | Total_Inc_Study$Age_Rounded=="N/A")
      #MISSING 1 AGE VALUE!

      sum(is.na(Total_Inc_Study$SES) | Total_Inc_Study$SES=="N/A")
      #MISSING 11 SES VALUES!
      
      Incorrect_SES <- subset(Total_Inc_Study, Total_Inc_Study$SES < 3) 
      nrow(Incorrect_SES) #NONE ARE INAPPROPRIATE
 
      
# SEX 
  sum(Total_Inc_Study$M.F=='Female') # 99
  sum(Total_Inc_Study$M.F=='Male') # 98
  sum(EE_Inc$M.F=='Female') # 24
  sum(EE_Inc$M.F=='Male') # 23
  sum(EL_Inc$M.F=='Female') # 25
  sum(EL_Inc$M.F=='Male') # 18
  sum(AE_Inc$M.F=='Female') # 27
  sum(AE_Inc$M.F=='Male') # 25
  sum(AL_Inc$M.F=='Female') # 23
  sum(AL_Inc$M.F=='Male') #32

# AGE DESCRIPTIVE STATISTICS
min(EE_Inc$Age_Rounded, na.rm=TRUE) # 5.1
min(EL_Inc$Age_Rounded, na.rm=TRUE) # 5
min(AE_Inc$Age_Rounded, na.rm=TRUE) # 5.2
min(AL_Inc$Age_Rounded, na.rm=TRUE) # 5.1
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, min) #Creates a table in one 

max(EE_Inc$Age_Rounded, na.rm=TRUE) # 9.7
max(EL_Inc$Age_Rounded, na.rm=TRUE) # 9.8
max(AE_Inc$Age_Rounded, na.rm=TRUE) # 9.9
max(AL_Inc$Age_Rounded, na.rm=TRUE) # 9.8
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, max) 

median(EE_Inc$Age_Rounded, na.rm=TRUE) # 6.7
median(EL_Inc$Age_Rounded, na.rm=TRUE) # 6.2
median(AE_Inc$Age_Rounded, na.rm=TRUE) # 7.05
median(AL_Inc$Age_Rounded, na.rm=TRUE) # 7.4
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, median)

mean(EE_Inc$Age_Rounded, na.rm=TRUE) # 6.917021
mean(EL_Inc$Age_Rounded, na.rm=TRUE) # 6.588095
mean(AE_Inc$Age_Rounded, na.rm=TRUE) # 7.355769
mean(AL_Inc$Age_Rounded, na.rm=TRUE) # 7.472727
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, mean)

sd(EE_Inc$Age_Rounded, na.rm=TRUE) # 1.304394
sd(EL_Inc$Age_Rounded, na.rm=TRUE) # 1.283707
sd(AE_Inc$Age_Rounded, na.rm=TRUE) # 1.526166
sd(AL_Inc$Age_Rounded, na.rm=TRUE) # 1.457859
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, sd)

range(EE_Inc$Age_Rounded, na.rm=TRUE) # 5.1 9.7
range(EL_Inc$Age_Rounded, na.rm=TRUE) # 5.0 9.8
range(AE_Inc$Age_Rounded, na.rm=TRUE) # 5.2 9.9
range(AL_Inc$Age_Rounded, na.rm=TRUE) # 5.1 9.8
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, range)

# SES DESCRIPTIVE STATISTICS
min(EE_Inc$SES, na.rm=TRUE) # 17
min(EL_Inc$SES, na.rm=TRUE) # 6
min(AE_Inc$SES, na.rm=TRUE) # 3
min(AL_Inc$SES, na.rm=TRUE) # 3
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, min)

max(EE_Inc$SES, na.rm=TRUE) # 66
max(EL_Inc$SES, na.rm=TRUE) # 66
max(AE_Inc$SES, na.rm=TRUE) # 62
max(AL_Inc$SES, na.rm=TRUE) # 63.5
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, max)

median(EE_Inc$SES, na.rm=TRUE) # 61
median(EL_Inc$SES, na.rm=TRUE) # 53
median(AE_Inc$SES, na.rm=TRUE) # 48.25
median(AL_Inc$SES, na.rm=TRUE) # 47
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, median)

mean(EE_Inc$SES, na.rm=TRUE) # 56.20213
mean(EL_Inc$SES, na.rm=TRUE) # 48.21951
mean(AE_Inc$SES, na.rm=TRUE) # 43.83333
mean(AL_Inc$SES, na.rm=TRUE) # 42.38
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, mean)

sd(EE_Inc$SES, na.rm=TRUE) # 12.37005
sd(EL_Inc$SES, na.rm=TRUE) # 13.92078
sd(AE_Inc$SES, na.rm=TRUE) # 14.43155
sd(AL_Inc$SES, na.rm=TRUE) # 15.97305
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, sd)

range(EE_Inc$SES, na.rm=TRUE) # 17.0 66
range(EL_Inc$SES, na.rm=TRUE) # 3 66
range(AE_Inc$SES, na.rm=TRUE) # 3 62
range(AL_Inc$SES, na.rm=TRUE) # 3 63.5
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, range)


#CREATING TIMING/MODALITY DATA FRAMES
#TIMING GROUPS
Early <- subset(Total_Inc_Study, Total_Inc_Study$Timing == "Early")
Later <- subset(Total_Inc_Study, Total_Inc_Study$Timing == "Later")
#MODALITY GROUPS
ASL <- subset(Total_Inc_Study, Total_Inc_Study$Modality == "ASL")
English <- subset(Total_Inc_Study, Total_Inc_Study$Modality == "English")

#VARIABLE SHORTCUTS#  
Age <- Total_Inc_Study$Age_Rounded
SES <- Total_Inc_Study$SES

## TIMING VIOLIN PLOTS ## 
      TimeGrp <- Total_Inc_Study$Timing
      # TIMING: AGE 
      ggplot(Total_Inc_Study, aes(x=TimeGrp, y=Age)) + geom_violin() + labs(x="Language Timing", y="Age(years)") 
      #VISUALLY VERY SIMILAR DISTRIBUTIONS
      # TIMING: SES
      ggplot(Total_Inc_Study, aes(x=TimeGrp, y=SES)) + geom_violin() + labs(x="Language Timing", y="SES") 
      #VISUALLY VERY SIMILAR DISTRIBUTIONS

## MODALITY VIOLIN PLOTS ##
      ModalityGrp <- Total_Inc_Study$Modality
      # MODALITY: AGE
      ggplot(Total_Inc_Study, aes(x=ModalityGrp, y=Age)) + geom_violin() + labs(x="Language Modality", y="Age(years)")
      #ASL HAS MORE EVEN AGE DISTRIBUTION, ENGLISH HAS < OLDER KIDS
      # MODALITY: SES
      ggplot(Total_Inc_Study, aes(x=ModalityGrp, y=SES)) + geom_violin() + labs(x="Language Modality", y="SES")
      #ENGLISH MORE "TOP HEAVY" FOR SES
 
## GROUP VIOLIN PLOTS ## 
      Groups <- Total_Inc_Study$Group_4cat
      map.n <- function(x){return(c(y = median(x)*1.05, label = length(x))) }
      mean.n <- function(x){return(c(y= median(x)*0.97, label = round(mean(x), 2)))}   
     #4 GROUPS:AGE
      ggplot(Total_Inc_Study, aes(x=Groups, y=Age, fill = Groups)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Experimental Groups", y = "Age (years)") + stat_summary(fun.data = mean.n, geom = "text", fun.y = median) + stat_summary(fun.data = mean.n, geom= "text", fun.y=mean, color= "gainsboro") + theme(legend.position="none") 
      #LOOKS GREAT!

      #4 GROUPS:SES
    ggplot(Total_Inc_Study, aes(x=Groups, y=SES, fill = Groups)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Experimental Groups", y = "SES") + stat_summary(fun.data = mean.n, geom = "text", fun.y = median) + stat_summary(fun.data = mean.n, geom= "text", fun.y=mean, color= "gainsboro") + theme(legend.position="none")
    #ENGLISH GROUPS HIGHER SES/"TOP HEAVY"
 
 
 
# ANOVA for mean Age and mean SES between groups - is the avergae age or SES sig different between groups?
#AGE#
      # mean Age
      # Ho : mu1=...=mu4
      # Ha : mu2=...≠...mu4
      # alpha level: 0.05     
# RUN THAT ANOVA 
Age_ANOVA <- aov(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Group_4cat)
summary(Age_ANOVA) # p=0.0089 #NOT EQUAL BETWEEN GROUPS!
      # If > 0.5, conclude that population means for Age are equal between groups
      # If <0.05, reject null, conclude that population means for Age are not equal between groups, which ones differ?
            #Post-Hoc
                  par(ask=TRUE)
                  opar <- par(no.readonly=TRUE) 
                  TukeyHSD(Age_ANOVA)
                  par(las=1) 
                  par(mar=c(5,8,4,2)) 
                  plot(TukeyHSD(Age_ANOVA))
                  par(opar)
       
       #NEED TO FIGURE OUT HOW TO INTERPRET THE OUTPUT!#

# Assumptions to be able to USE ANOVA  
      #1. Normality   - NOT PASS
      qqPlot(Age_ANOVA) #qq plot: scatterplot of observed vs expected normality and want linear line 
      Age_residuals <- residuals(Age_ANOVA) #residual: all data's mean then overall mean subtracted from each data point (indiv-datasetmean)
      shapiro.test(Age_residuals) #do not reject null, assume normality aka bell curve? WANT THAT HIGH P = normally distributed
      ##p-value = 1.381e-05, NOT NORMALLY DISTRIBUTED!
      ggdensity(Total_Inc_Study$Age_Rounded, main = "Density plot of AGE", xlab = "Age (years)") #NOT A BELL CURVE!
      #BY GROUPS:
      shapiro.test(EE_Inc$Age_Rounded) #p-value = 0.01202<0.05, reject null, can't assume normality
      shapiro.test(AE_Inc$Age_Rounded)#p-value = 0.002556<0.05, reject null, can't assume normality
      shapiro.test(EL_Inc$Age_Rounded)#p-value = 0.003191<0.05, reject null, can't assume normality
      shapiro.test(AL_Inc$Age_Rounded)#p-value = 0.009083<0.05, reject null, can't assume normality

      #2. Homeogeneity of Variances Between Groups    -PASS
      bartlett.test(Total_Inc_Study$Age_Rounded, Total_Inc_Study$Group_4cat) # p=0.5755, HAVE HOMOGENEITY
            # IF p > 0.5 WANT THAT HIGH P! = HOMOGENEITY ACHIEVED
            # IF p<0.05, reject the null hypothesis, do not assume variances are equal, is the variance for each of the groups similar? 
      plot(Age_ANOVA,1) #x-axis all indiv group means and for each group mean has observations and how spread from group mean, want bands to have same spread aka start and end points 
      #PLOT LOOKS GOOD, SIMILAR SPREAD
     
      #BY GROUPS:
      bartlett.test(Age_Rounded ~ Group_4cat, data=Total_Inc_Study) # p= 0.5755
      leveneTest(Age_Rounded ~ Group_4cat, data=Total_Inc_Study) #p= 0.2832

# IF SHAPIRO AND BARLETT ARE >.O5 YAH GOOD, IF NOT: LEVENE AS BACKUP FOR BARLETT, IF STILL NAH, NON-PARAMETRIC METHOD NEEDS TO BE USED / NOT ANOVA 
      # Violated variances assumption, re-run using kruskal-wallis test (non-parametric)
      # IF ASSUMPTIONS DO NOT HOLD, USE KRUSKAL NON-PARAMATRIC TEST/PAIRWISE.WILCOX.TEST FOR POST-HOC)
      kruskal.test(Total_Inc_Study$Age_Rounded ~ Group_4cat, data = Total_Inc_Study)
      pairwise.wilcox.test(Total_Inc_Study$Age, Total_Inc_Study$Group_4cat, p.adjust.method="none")
      # Which p-value adjustment method should be used?

*********************************
#SES#
            # mean SES
            # Ho : mu1=...=mu4
            # Ha : mu2=...≠...mu4
            # alpha level: 0.05
            # Assumptions

# All samples drawn independently
SES_ANOVA <- aov(Total_Inc_Study$SES ~ Total_Inc_Study$Group_4cat)
summary(SES_ANOVA) # p = 1.26e-05 #SES MEANS ARE NOT EQUAL BETWEEN GROUPS
      # p=IF>0.05, do not reject null, conclude that population means for SES are equal between groups

      #If different, perform Post-Hoc: 
      par(ask=TRUE)
      opar <- par(no.readonly=TRUE) 
      TukeyHSD(SES_ANOVA)
      par(las=1) 
      par(mar=c(5,8,4,2)) 
      plot(TukeyHSD(SES_ANOVA))
      par(opar)

      #1. Normality  
      qqPlot(SES_ANOVA)
      SES_residuals <- residuals(SES_ANOVA) 
      shapiro.test(SES_residuals) #p-value = 1.597e-11 #NOT NORMALLY DISTRIBUTED
      ggdensity(Total_Inc_Study$SES, main = "Density plot of SES", xlab = "SES") #RIGHT SKEWED
      #BY GROUPS: #ALSO ALL < 0.05
            shapiro.test(EE_Inc$SES)
            shapiro.test(EL_Inc$SES) 
            shapiro.test(AE_Inc$SES) 
            shapiro.test(AL_Inc$SES) 
  
      #2. Homeogeneity of Variances Between Groups
      bartlett.test(Total_Inc_Study$SES, Total_Inc_Study$Group_4cat) # p >0.05, do not reject the null hypothesis, assume variances are equal
      plot(SES_ANOVA,1) #x-axis all indiv group means and for each group mean has observations and how spread from group mean, want bands to have same spread aka start and end points 
      
      bartlett.test(SES ~ Group_4cat, data=Total_Inc_Study) # p-value = 0.3807
      
      leveneTest(SES ~ Group_4cat, data=Total_Inc_Study) #p = 0.08446

# IF FAIL ABOVE ASSUMPTIONS, SWITCH TO NON-PARAMETRIC TEST # 
kruskal.test(SES ~ Group_4cat, data = Total_Inc_Study)
pairwise.wilcox.test(Total_Inc_Study$SES,Total_Inc_Study$Group_4cat,p.adjust.method="none")


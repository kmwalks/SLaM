#1. Install and Load Libraries 

install.packages("car")
install.packages("sm")
install.packages("ggplot2") # for general plots
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages ("olsrr") #for testing normality

library(ggplot2) 
library(MASS) 
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(olsrr)
library(car)
library(sm)


#2. Check and Set Working Directory
      setwd("~/Desktop")
      getwd()      
      
#3. Import Data [[make sure is most recent version and saved as csv]]
      Map <- read.csv("Mapping_Coding_KW_200130.csv", na.strings = "N/A")
      View(Map)   

## BASIC DEMOGRAPHICS ## 

      Map_Demo <- subset(Map, Map$Age_Rounded<10 | is.na(Map$Age_Rounded))
      View(Map_Demo) # 214 total kids

      Total_Inc_Study <- subset(Map_Demo, Map_Demo$Including.in.Study == "Yes")
      View(Total_Inc_Study)
      # 182 total kids included in study  
      
      ## Included: Numbers of Kids Per Group ##
      EE_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Early")
      View(EE_Inc)
      # 42 of 182 kids included are EE
      EL_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Later")
      View(EL_Inc)
      # 30 of 182 kids included are EL
      AE_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "ASL Early")
      View(AE_Inc)
      # 52 of 182 kids included are AE
      AL_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "ASL Later")
      View(AL_Inc)
      # 58 of 182 kids included are AL
      
   
      Total_Not_Inc_Study <- subset(Map_Demo, Map_Demo$Including.in.Study == "No")
      nrow(Total_Not_Inc_Study)
      View(Total_Not_Inc_Study)
      # 13 total kids not included in study
           
      Total_Blank_NA <- subset(Map_Demo, Map_Demo$Including.in.Study == "" | is.na(Map_Demo$Including.in.Study))
      View(Total_Blank_NA)
      # 19 blanks or N/As

      Tested_Not_Inc <- subset(Map_Demo, Map_Demo$Including.in.Study != "Yes" & Map_Demo$Date.Tested != "")
      View(Tested_Not_Inc)
      # 3 kid out of 13 not included in study were tested, NEED TO EXPLAIN WHY NOT INCLUDING! All had additional disabilities/suspected disabilities

      ## Tested But Not Included: How many from each group? ## 
            EE_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Group_4cat == "English Early" & Total_Not_Inc_Study$Date.Tested != "")
            View(EE_Not_Inc)
            # 0 of 13 kids tested but not included are EE
            EL_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Group_4cat == "English Later" & Total_Not_Inc_Study$Date.Tested != "")
            View(EL_Not_Inc)
            # 0 of 13 kids tested but not included are EL
            AE_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Group_4cat == "ASL Early" & Total_Not_Inc_Study$Date.Tested != "")
            View(AE_Not_Inc)
            # 1 of 13 kids tested but not included are AE
            AL_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Group_4cat == "ASL Later" & Total_Not_Inc_Study$Date.Tested != "")
            View(AL_Not_Inc)
            # 2 of 13 kids tested but not included are AL
            
      Rest_Not_Inc <- subset(Total_Not_Inc_Study, is.na(Total_Not_Inc_Study$Date.Tested))
      View(Rest_Not_Inc)
      # 10 remaining kids listed as not included were not tested

## Creating a Table/"Matrix": Included vs Not (& not tested) by Group ##

      rnames <- c("Including in Study","Not Including in Study")
      cnames <- c("English Early","English Later","ASL Early","ASL Later")
      Table_IncStudy <- matrix(c(nrow(EE_Inc),nrow(EL_Inc),nrow(AE_Inc),nrow(AL_Inc),nrow(EE_Not_Inc),nrow(EL_Not_Inc),nrow(AE_Not_Inc),nrow(AL_Not_Inc)), nrow=2, ncol=4, byrow=TRUE, dimnames=list(rnames,cnames))
      Table_IncStudy


## Chi-Square on Table/"Matrix": Does the status of including in study depend on which group kids were in?, aka DNS more likely to not be included? ##
chisq.test(Table_IncStudy)
# Test statistic is p-value is 0.5469, do not reject null, conclude that status of inclusion in study is not dependent on group 4 category. GOOD.

# Find observations with missing Age and SES values
      which(is.na(Total_Inc_Study$Age_Rounded)) # 0 observations missing Age value
      Missing_Age <- Total_Inc_Study[which(is.na(Total_Inc_Study$Age_Rounded)),3]
      View(Missing_Age)

      which(is.na(Total_Inc_Study$SES)) # 9 observations missing SES value
      Missing_SES <- Total_Inc_Study[which(is.na(Total_Inc_Study$SES_range_8_to_66)),3]
      View(Missing_SES)
      
      Incorrect_SES <- subset(Map_Demo, Map_Demo$SES_range_8_to_66 < 3 | Map_Demo$SES_range_8_to_66 == "") #No observations of SES <3
      View(Incorrect_SES)
      
      
# SEX 
  sum(Total_Inc_Study$M.F=='Female') # 57
  sum(Total_Inc_Study$M.F=='Male') # 73
  sum(EE_Inc$M.F=='Female') # 20
  sum(EE_Inc$M.F=='Male') # 22
  sum(EL_Inc$M.F=='Female') # 5
  sum(EL_Inc$M.F=='Male') # 5
  sum(AE_Inc$M.F=='Female') # 14
  sum(AE_Inc$M.F=='Male') # 19
  sum(AL_Inc$M.F=='Female') # 18
  sum(AL_Inc$M.F=='Male') #27

# AGE DESCRIPTIVE STATISTICS
min(EE_Inc$Age_Rounded, na.rm=TRUE) # 5.1
min(EL_Inc$Age_Rounded, na.rm=TRUE) # 6.1
min(AE_Inc$Age_Rounded, na.rm=TRUE) # 5.2
min(AL_Inc$Age_Rounded, na.rm=TRUE) # 5.1
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, min) #Creates a table in one 

max(EE_Inc$Age_Rounded, na.rm=TRUE) # 9.7
max(EL_Inc$Age_Rounded, na.rm=TRUE) # 9.8
max(AE_Inc$Age_Rounded, na.rm=TRUE) # 9.9
max(AL_Inc$Age_Rounded, na.rm=TRUE) # 9.8
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, max) 

median(EE_Inc$Age_Rounded, na.rm=TRUE) # 6.9
median(EL_Inc$Age_Rounded, na.rm=TRUE) # 7.4
median(AE_Inc$Age_Rounded, na.rm=TRUE) # 6.7
median(AL_Inc$Age_Rounded, na.rm=TRUE) # 7.4
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, median)

mean(EE_Inc$Age_Rounded, na.rm=TRUE) # 6.985714
mean(EL_Inc$Age_Rounded, na.rm=TRUE) # 7.48
mean(AE_Inc$Age_Rounded, na.rm=TRUE) # 7.142424
mean(AL_Inc$Age_Rounded, na.rm=TRUE) # 7.386667
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, mean)

sd(EE_Inc$Age_Rounded, na.rm=TRUE) # 1.319381
sd(EL_Inc$Age_Rounded, na.rm=TRUE) # 1.323128
sd(AE_Inc$Age_Rounded, na.rm=TRUE) # 1.619033
sd(AL_Inc$Age_Rounded, na.rm=TRUE) # 1.471178
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, sd)

range(EE_Inc$Age_Rounded, na.rm=TRUE) # 5.1 9.7
range(EL_Inc$Age_Rounded, na.rm=TRUE) # 6.1 9.8
range(AE_Inc$Age_Rounded, na.rm=TRUE) # 5.2 9.9
range(AL_Inc$Age_Rounded, na.rm=TRUE) # 5.1 9.8
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, range)

# SES DESCRIPTIVE STATISTICS
min(EE_Inc$SES_range_8_to_66, na.rm=TRUE) # 17
min(EL_Inc$SES_range_8_to_66, na.rm=TRUE) # 6
min(AE_Inc$SES_range_8_to_66, na.rm=TRUE) # 3
min(AL_Inc$SES_range_8_to_66, na.rm=TRUE) # 3
aggregate(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study, min)

max(EE_Inc$SES_range_8_to_66, na.rm=TRUE) # 66
max(EL_Inc$SES_range_8_to_66, na.rm=TRUE) # 66
max(AE_Inc$SES_range_8_to_66, na.rm=TRUE) # 62
max(AL_Inc$SES_range_8_to_66, na.rm=TRUE) # 63.5
aggregate(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study, max)

median(EE_Inc$SES_range_8_to_66, na.rm=TRUE) # 61
median(EL_Inc$SES_range_8_to_66, na.rm=TRUE) # 51.75
median(AE_Inc$SES_range_8_to_66, na.rm=TRUE) # 47
median(AL_Inc$SES_range_8_to_66, na.rm=TRUE) # 45
aggregate(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study, median)

mean(EE_Inc$SES_range_8_to_66, na.rm=TRUE) # 55.5
mean(EL_Inc$SES_range_8_to_66, na.rm=TRUE) # 47.6
mean(AE_Inc$SES_range_8_to_66, na.rm=TRUE) # 44.06897
mean(AL_Inc$SES_range_8_to_66, na.rm=TRUE) # 40.275
aggregate(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study, mean)

sd(EE_Inc$SES_range_8_to_66, na.rm=TRUE) # 12.89923
sd(EL_Inc$SES_range_8_to_66, na.rm=TRUE) # 15.66986
sd(AE_Inc$SES_range_8_to_66, na.rm=TRUE) # 14.50476
sd(AL_Inc$SES_range_8_to_66, na.rm=TRUE) # 16.57769
aggregate(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study, sd)

range(EE_Inc$SES_range_8_to_66, na.rm=TRUE) # 17 66
range(EL_Inc$SES_range_8_to_66, na.rm=TRUE) # 6 66
range(AE_Inc$SES_range_8_to_66, na.rm=TRUE) # 3 62
range(AL_Inc$SES_range_8_to_66, na.rm=TRUE) # 3 63.5
aggregate(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study, range)

## TIMING VIOLIN PLOTS ## 
      # TIMING: AGE 
      TimingGroup <- subset(Total_Inc_Study, Total_Inc_Study$Timing_cat == "Early" | Total_Inc_Study$Timing_2cat == "Later") 
      TimeGrp <- Total_Inc_Study$Timing_cat
      ggplot(TimingGroup, aes(x=TimeGrp, y=Total_Inc_Study$Age_Rounded)) + geom_violin() + labs(x="Timing", y="Age(years)")

      # TIMING: SES
      TimingGroup <- subset(Total_Inc_Study, Total_Inc_Study$Timing_cat == "Early" | Total_Inc_Study$Timing_2cat == "Later")
      TimeGrp <- Total_Inc_Study$Timing_cat
      ggplot(TimingGroup, aes(x=TimeGrp, y=Total_Inc_Study$SES_range_8_to_66)) + geom_violin() + labs(x="Timing", y="SES")

## MODALITY VIOLIN PLOTS ##
      # MODALITY: AGE
      ModalityGroup <- subset(Total_Inc_Study, Total_Inc_Study$Modality_cat == "English" | Total_Inc_Study$Modality_cat == "ASL")
      ModalityGrp <- Total_Inc_Study$Modality_cat
      ggplot(ModalityGroup, aes(x=ModalityGrp, y=Total_Inc_Study$Age_Rounded)) + geom_violin() + labs(x="Modality", y="Age(years)")

      # MODALITY: SES
      ModalityGroup <- subset(Total_Inc_Study, Total_Inc_Study$Modality_cat == "English" | Total_Inc_Study$Modality_cat == "ASL")
      ModalityGrp <- Total_Inc_Study$Modality_cat
      ggplot(ModalityGroup, aes(x=ModalityGrp, y=Total_Inc_Study$SES_range_8_to_66)) + geom_violin() + labs(x="Modality", y="SES")
      
## GROUP VIOLIN PLOTS ## 
      # AGE
      LngGrp <- cbind(Total_Inc_Study, LanguageGroup) 
      View(LngGrp)

      map.n <- function(x){return(c(y = median(x)*1.05, label = length(x))) }
      mean.n <- function(x){return(c(y= median(x)*0.97, label = round(mean(x), 2)))}
      ggplot(LngGrp, aes(x = LanguageGroup, y = LngGrp$SES_range_8_to_66, fill = LanguageGroup)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Language Group", y = "SES") + stat_summary(fun.data = mean.n, geom = "text", fun.y = median) + stat_summary(fun.data = mean.n, geom= "text", fun.y=mean, color= "gainsboro") + theme(legend.position="none") 

      # SES
      LngGrp <- cbind(Total_Inc_Study, LanguageGroup) 
      View(LngGrp)
      map.n <- function(x){return(c(y = median(x)*1.05, label = length(x))) }
      mean.n <- function(x){return(c(y= median(x)*0.97, label = round(mean(x), 2)))}
      ggplot(LngGrp, aes(x = LanguageGroup, y = LngGrp$Age_Rounded, fill = LanguageGroup)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Language Group", y = "Age (years)") + stat_summary(fun.data = mean.n, geom = "text", fun.y = median) + stat_summary(fun.data = mean.n, geom= "text", fun.y=mean, color= "gainsboro") + theme(legend.position="none") 
   
   
#DENSITY PLOT BELOW, NOT WORKING NEED LIBRARY FOR SM.DENSITY.COMPARE
Labels <- factor(Total_Inc_Study$Group_4cat, levels=c("English Early","English Later","ASL Early","ASL Later"), labels = c("English Early","English Later","ASL Early","ASL Later"))
sm.density.compare(Total_Inc_Study$SES_range_8_to_66, Total_Inc_Study$Group_4cat, xlab="Socioeconomic Status", lwd=3,xlim=c(3,66),col=c(4,6,2,3))
title(main="SES Distribution for each Group 4 Category")
colfill<-c(2,3,4,6)
legend(3,0.033, levels(Labels), fill=colfill)


      
# ANOVA for mean Age and mean SES between groups - is the avergae age or SES sig different between groups?

#AGE#
      # mean Age
      # Ho : mu1=...=mu4
      # Ha : mu2=...≠...mu4
      # alpha level: 0.05
      
      
# RUN THAT ANOVA
Age_ANOVA <- aov(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Group_4cat)
summary(Age_ANOVA) # p=0.56
      # If > 0.5, conclude that population means for Age are equal between groups
      # If <0.05, reject null, conclude that population means for Age are not equal between groups, which ones differ?
            #Post-Hoc
                  par(ask=TRUE)
                  opar <- par(no.readonly=TRUE) 
                  TukeyHSD(Age_ANOVA)
                  par(las=1) 
                  par(mar=c(5,8,4,2)) 
                  plot(TukeyHSD(Age_ANOVA))
                  par(opar)

# Assumptions to be able to USE ANOVA
      #THINK NEED LIBRARY MASS TO GET QQPLOT....GETTING ERRORS!
      
      #1. Normality   
      qqPlot(Age_ANOVA) #qq plot: scatterplot of observed vs expected normality and want linear line (match up)
      
      Age_residuals <- residuals(Age_ANOVA) #residual: all data's mean then overall mean subtracted from each data point (indiv-datasetmean)
      shapiro.test(Age_residuals) #do not reject null, assume normality aka bell curve? WANT THAT HIGH P = normally distributed
      
      #2. Homeogeneity of Variances Between Groups
      bartlett.test(Total_Inc_Study$Age_Rounded, Total_Inc_Study$Group_4cat) # p=0.299
            # IF p > 0.5 WANT THAT HIGH P! = HOMOGENEITY ACHIEVED
            # IF p<0.05, reject the null hypothesis, do not assume variances are equal, is the variance for each of the groups similar?
       
      plot(Age_ANOVA,1) #x-axis all indiv group means and for each group mean has observations and how spread from group mean, want bands to have same spread aka start and end points 
      
      bartlett.test(Age_Rounded ~ Group_4cat, data=Total_Inc_Study) # p =0.3
      
      leveneTest(Age_Rounded ~ Group_4cat, data=Total_Inc_Study) 

# IF SHAPIRO AND BARLETT ARE >.O5 YAH GOOD, IF NOT: LEVENE AS BACKUP FOR BARLETT, IF STILL NAH, NON-PARAMETRIC METHOD NEEDS TO BE USED / NOT ANOVA 
      # Violated variances assumption, re-run using kruskal-wallis test (non-parametric)
      # IF ASSUMPTIONS DO NOT HOLD, USE KRUSKAL NON-PARAMATRIC TEST/PAIRWISE.WILCOX.TEST FOR POST-HOC)
      kruskal.test(Total_Inc_Study$Age_Rounded ~ Group_4cat, data = Total_Inc_Study)
      pairwise.wilcox.test(Total_Inc_Study$Age, Total_Inc_Study$Group_4cat, p.adjust.method="none")
      # Which p-value adjustment method should be used?

*********************************
#SES#
            # mean SES
            # Ho : mu1=...=mu4
            # Ha : mu2=...≠...mu4
            # alpha level: 0.05
            # Assumptions

# All samples drawn independently
SES_ANOVA <- aov(Total_Inc_Study$SES_range_8_to_66 ~ Total_Inc_Study$Group_4cat)
summary(SES_ANOVA) # p < 0.0001
      # p=IF>0.05, do not reject null, conclude that population means for SES are equal between groups

      #If different, perform Post-Hoc: 
      par(ask=TRUE)
      opar <- par(no.readonly=TRUE) 
      TukeyHSD(SES_ANOVA)
      par(las=1) 
      par(mar=c(5,8,4,2)) 
      plot(TukeyHSD(SES_ANOVA))
      par(opar)

      #1. Normality  
      qqPlot(SES_ANOVA)
      SES_residuals <- residuals(SES_ANOVA)
      shapiro.test(SES_residuals)
            shapiro.test(EE_Inc$SES_range_8_to_66) # p=2.668e-07<0.05, reject null, can't assume normality
            shapiro.test(EL_Inc$SES_range_8_to_66) # p=0.002325<0.05, reject null, can't assume normality
            shapiro.test(AE_Inc$SES_range_8_to_66) # p=0.01088<0.05, reject null, can't assume normality
            shapiro.test(AL_Inc$SES_range_8_to_66) # p=0.002279<0.05, reject null, can't assume normality
            # This assumption really fell apart
      
      #2. Homeogeneity of Variances Between Groups
      bartlett.test(Total_Inc_Study$SES_range_8_to_66, Total_Inc_Study$Group_4cat) # p >0.05, do not reject the null hypothesis, assume variances are equal
      plot(SES_ANOVA,1) #x-axis all indiv group means and for each group mean has observations and how spread from group mean, want bands to have same spread aka start and end points 
      
      bartlett.test(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study) # p =0.4697
      
      leveneTest(SES_range_8_to_66 ~ Group_4cat, data=Total_Inc_Study)

# IF FAIL ABOVE ASSUMPTIONS, SWITCH TO NON-PARAMETRIC TEST # 
kruskal.test(SES_range_8_to_66~ Group_4cat, data = Total_Inc_Study)
pairwise.wilcox.test(Total_Inc_Study$SES_range_8_to_66,Total_Inc_Study$Group_4cat,p.adjust.method="none")


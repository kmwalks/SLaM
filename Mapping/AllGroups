#Install and Load Libraries 

install.packages("car")
install.packages("sm")
install.packages("ggplot2") # for general plots
install.packages("MASS") # for polr package
install.packages("generalhoslem") # for testing model fit (lipsitz test and two others)
install.packages("qwraps2") # for summary_table use
install.packages("quantreg") # testing quantile plots (geom_quantile) and quantile regressions
install.packages ("olsrr") #for testing normality
install.packages("ggpubr") #for density plots
install.packages("dplyr")
install.packages("tidyr")
install.packages("lme4")

library(ggplot2) 
library(MASS) 
library(generalhoslem) 
library(qwraps2) 
library(quantreg) 
library(olsrr)
library(car)
library(sm)
library(ggpubr)
library(dplyr)
library(tidyr)
library(lme4)

#Import Data 
      setwd("~/Desktop")   
      Map <- read.csv("Mapping_Coding_KW_200414.csv", na.strings = "N/A")
      View(Map) #224 kids  

## BASIC DEMOGRAPHICS ## 
      Map_Demo <- subset(Map, Map$Age_Rounded>=4.5 & Map$Age_Rounded<=10 | is.na(Map$Age_Rounded))
      View(Map_Demo) # 220 kids total ages 4.5-9 (including kids we never tested)

#FOR DEMOGRAPHICS OF ALL POSSIBLE KIDS INCLUDING FOR MAPPING 
      Total_Inc_Study <- subset(Map_Demo, Map_Demo$Including.in.Study == "Yes" & Map_Demo$Coded. == "Yes" & Map_Demo$Mapping_Include. == "Yes")
      View(Total_Inc_Study)
      # 200 total kids included in study  
      
      ## Included OVERALL: Numbers of Kids Per Group ##
      EE_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Early")
      View(EE_Inc) #48
      EL_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Later")
      View(EL_Inc) #47
      AE_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "ASL Early")
      View(AE_Inc) #50
      AL_Inc <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "ASL Later")
      View(AL_Inc) #55
      
      Total_Not_Inc_Study <- subset(Map_Demo, Map_Demo$Mapping_Include. == "No")
      nrow(Total_Not_Inc_Study)
      View(Total_Not_Inc_Study)
      # 20 total kids not included in mapping analyses (if not included in study overall, not including in mapping)
                     
      Total_NotTested_NA <- subset(Map_Demo,  Map_Demo$Tested == "No" | Map_Demo$Tested == "Not Yet" | is.na(Map_Demo$Including.in.Study))
      View(Total_NotTested_NA)
      # 15 Not Tested 
      
      NotTested_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Tested == "No")
      nrow(NotTested_Not_Inc)
      #15 remaining kids listed as not included were not tested
      
      Tested_Not_Inc <- subset(Total_Not_Inc_Study, Total_Not_Inc_Study$Tested == "Yes")
      View(Tested_Not_Inc)
      # 5 kid out of 15 not included in study were tested
      #3 had additional disabilities/suspected disabilities, 1 refused to participate, 1 due to technical difficulties (not filmed entirely)

      ## Tested But Not Included: How many from each group? ## 
            EE_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "English Early")
            nrow(EE_Not_Inc) # 0 of 5 kids tested but not included are EE
            EL_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "English Later")
            nrow(EL_Not_Inc) # 0 of 5 kids tested but not included are EL
            AE_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "ASL Early")
            nrow(AE_Not_Inc)# 3 of 5 kids tested but not included are AE
            AL_Not_Inc <- subset(Tested_Not_Inc, Tested_Not_Inc$Group_4cat == "ASL Later")
            nrow(AL_Not_Inc) # 2 of 5 kids tested but not included are AL
   

## Creating a Table/"Matrix": Included vs Not (& not tested) by Group ##

      rnames <- c("Including in Study","Not Including in Study")
      cnames <- c("English Early","English Later","ASL Early","ASL Later")
      Table_IncStudy <- matrix(c(nrow(EE_Inc),nrow(EL_Inc),nrow(AE_Inc),nrow(AL_Inc),nrow(EE_Not_Inc),nrow(EL_Not_Inc),nrow(AE_Not_Inc),nrow(AL_Not_Inc)), nrow=2, ncol=4, byrow=TRUE, dimnames=list(rnames,cnames))
      Table_IncStudy

## Chi-Square on Table/"Matrix": Does the status of including in study depend on which group kids were in?, aka Early ASL more likely to not be included? ##
chisq.test(Table_IncStudy)
# Test statistic is X-squared = 4.9604, df = 3, p-value = 0.1747, do not reject null, conclude that status of inclusion in study is not dependent on group 4 category

# Find observations with missing Age and SES values
      sum(is.na(Total_Inc_Study$Age_Rounded) | Total_Inc_Study$Age_Rounded=="N/A")
      #Not missing any age values

      sum(is.na(Total_Inc_Study$SES) | Total_Inc_Study$SES=="N/A")
      #Missing 9 SES values
      
      Incorrect_SES <- subset(Total_Inc_Study, Total_Inc_Study$SES < 3) 
      nrow(Incorrect_SES) #NONE ARE INAPPROPRIATE
 
      
# SEX 
  sum(Total_Inc_Study$M.F=='Female') # 103
  sum(Total_Inc_Study$M.F=='Male') # 97
  sum(EE_Inc$M.F=='Female') # 25
  sum(EE_Inc$M.F=='Male') # 23
  sum(EL_Inc$M.F=='Female') # 27
  sum(EL_Inc$M.F=='Male') # 20
  sum(AE_Inc$M.F=='Female') # 28
  sum(AE_Inc$M.F=='Male') # 22
  sum(AL_Inc$M.F=='Female') # 23
  sum(AL_Inc$M.F=='Male') #32

# AGE DESCRIPTIVE STATISTICS
min(EE_Inc$Age_Rounded, na.rm=TRUE) # 4.8
min(EL_Inc$Age_Rounded, na.rm=TRUE) #4.5
min(AE_Inc$Age_Rounded, na.rm=TRUE) # 5.2
min(AL_Inc$Age_Rounded, na.rm=TRUE) # 5.1
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, min) #Creates a table in one 

max(EE_Inc$Age_Rounded, na.rm=TRUE) # 9.7
max(EL_Inc$Age_Rounded, na.rm=TRUE) # 9.8
max(AE_Inc$Age_Rounded, na.rm=TRUE) # 9.9
max(AL_Inc$Age_Rounded, na.rm=TRUE) # 9.8
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, max) 

median(EE_Inc$Age_Rounded, na.rm=TRUE) # 6.7
median(EL_Inc$Age_Rounded, na.rm=TRUE) # 6.2
median(AE_Inc$Age_Rounded, na.rm=TRUE) # 7.3
median(AL_Inc$Age_Rounded, na.rm=TRUE) # 7.4
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, median)

mean(EE_Inc$Age_Rounded, na.rm=TRUE) # 6.87
mean(EL_Inc$Age_Rounded, na.rm=TRUE) # 6.41
mean(AE_Inc$Age_Rounded, na.rm=TRUE) # 7.43
mean(AL_Inc$Age_Rounded, na.rm=TRUE) # 7.47
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, mean)

sd(EE_Inc$Age_Rounded, na.rm=TRUE) # 1.33
sd(EL_Inc$Age_Rounded, na.rm=TRUE) # 1.33
sd(AE_Inc$Age_Rounded, na.rm=TRUE) # 1.51
sd(AL_Inc$Age_Rounded, na.rm=TRUE) # 1.46
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, sd)

range(EE_Inc$Age_Rounded, na.rm=TRUE) # 4.8 9.7
range(EL_Inc$Age_Rounded, na.rm=TRUE) # 4.5 9.8
range(AE_Inc$Age_Rounded, na.rm=TRUE) # 5.2 9.9
range(AL_Inc$Age_Rounded, na.rm=TRUE) # 5.1 9.8
aggregate(Age_Rounded ~ Group_4cat, data=Total_Inc_Study, range)

# SES DESCRIPTIVE STATISTICS
min(EE_Inc$SES, na.rm=TRUE) # 17
min(EL_Inc$SES, na.rm=TRUE) # 3
min(AE_Inc$SES, na.rm=TRUE) # 3
min(AL_Inc$SES, na.rm=TRUE) # 3
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, min)

max(EE_Inc$SES, na.rm=TRUE) # 66
max(EL_Inc$SES, na.rm=TRUE) # 66
max(AE_Inc$SES, na.rm=TRUE) # 62
max(AL_Inc$SES, na.rm=TRUE) # 63.5
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, max)

median(EE_Inc$SES, na.rm=TRUE) # 61
median(EL_Inc$SES, na.rm=TRUE) # 52.75
median(AE_Inc$SES, na.rm=TRUE) # 49.50
median(AL_Inc$SES, na.rm=TRUE) # 47
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, median)

mean(EE_Inc$SES, na.rm=TRUE) # 56.25
mean(EL_Inc$SES, na.rm=TRUE) # 48.25
mean(AE_Inc$SES, na.rm=TRUE) # 43.85
mean(AL_Inc$SES, na.rm=TRUE) # 42.38
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, mean)

sd(EE_Inc$SES, na.rm=TRUE) # 12.32
sd(EL_Inc$SES, na.rm=TRUE) # 13.21
sd(AE_Inc$SES, na.rm=TRUE) # 14.59
sd(AL_Inc$SES, na.rm=TRUE) # 15.97
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, sd)

range(EE_Inc$SES, na.rm=TRUE) # 17 66
range(EL_Inc$SES, na.rm=TRUE) # 3 66
range(AE_Inc$SES, na.rm=TRUE) # 3 62
range(AL_Inc$SES, na.rm=TRUE) # 3 63.5
aggregate(SES ~ Group_4cat, data=Total_Inc_Study, range)

describe(Total_Inc_Study$SES) #overall skewness 
HBE <- subset(Total_Inc_Study, Total_Inc_Study$Group_4cat == "English Early") 
describe(HBE$SES) # skewness of -2.01 (SE =1.8)

#Age of Language Exposure
aggregate(Age.of.Exposure..mo..Language ~ Group_4cat, data=Total_Inc_Study, min)
aggregate(Age.of.Exposure..mo..Language ~ Group_4cat, data=Total_Inc_Study, max)
aggregate(Age.of.Exposure..mo..Language ~ Group_4cat, data=Total_Inc_Study, median)
aggregate(Age.of.Exposure..mo..Language ~ Group_4cat, data=Total_Inc_Study, mean)
aggregate(Age.of.Exposure..mo..Language ~ Group_4cat, data=Total_Inc_Study, sd)

#Race
sum(is.na(Total_Inc_Study$Race)) #16 N/As
nrow(filter(Total_Inc_Study, Race == "White")) #1401
nrow(filter(Total_Inc_Study, Race == "Black or African American")) #11
nrow(filter(Total_Inc_Study, Race == "American Indian or Alaska Native")) #3
nrow(filter(Total_Inc_Study, Race == "Asian")) #10
nrow(filter(Total_Inc_Study, Race == "Native Hawaiian or Other Pacific Islander")) #0
nrow(filter(Total_Inc_Study, Race == "Unsure")) #1
nrow(filter(Total_Inc_Study, Race == "Mixed")) #6
nrow(filter(Total_Inc_Study, Race == "Other")) #12
nrow(filter(Total_Inc_Study, Race == "")) #0

#Ethnicity
nrow(filter(Total_Inc_Study, Ethnicity == "Not Hispanic or Latino")) #118
nrow(filter(Total_Inc_Study, Ethnicity == "Hispanic or Latino")) #35
nrow(filter(Total_Inc_Study, Ethnicity == "")) #0
nrow(filter(Total_Inc_Study, Ethnicity == "Unsure")) #6
sum(is.na(Total_Inc_Study$Ethnicity)) #41

#CREATING TIMING/MODALITY DATA FRAMES
#TIMING GROUPS
Early <- subset(Total_Inc_Study, Total_Inc_Study$Timing == "Early")
Later <- subset(Total_Inc_Study, Total_Inc_Study$Timing == "Later")
#MODALITY GROUPS
ASL <- subset(Total_Inc_Study, Total_Inc_Study$Modality == "ASL")
English <- subset(Total_Inc_Study, Total_Inc_Study$Modality == "English")

#VARIABLE SHORTCUTS#  
Age <- Total_Inc_Study$Age_Rounded
SES <- Total_Inc_Study$SES

## TIMING VIOLIN PLOTS ## 
      TimeGrp <- Total_Inc_Study$Timing
      # TIMING: AGE 
      ggplot(Total_Inc_Study, aes(x=TimeGrp, y=Age)) + geom_violin() + labs(x="Language Timing", y="Age(years)") 
      #VISUALLY VERY SIMILAR DISTRIBUTIONS
      # TIMING: SES
      ggplot(Total_Inc_Study, aes(x=TimeGrp, y=SES)) + geom_violin() + labs(x="Language Timing", y="SES") 
      #VISUALLY VERY SIMILAR DISTRIBUTIONS

## MODALITY VIOLIN PLOTS ##
      ModalityGrp <- Total_Inc_Study$Modality
      # MODALITY: AGE
      ggplot(Total_Inc_Study, aes(x=ModalityGrp, y=Age)) + geom_violin() + labs(x="Language Modality", y="Age(years)")
      #ASL HAS MORE EVEN AGE DISTRIBUTION, ENGLISH HAS < OLDER KIDS
      # MODALITY: SES
      ggplot(Total_Inc_Study, aes(x=ModalityGrp, y=SES)) + geom_violin() + labs(x="Language Modality", y="SES")
      #ENGLISH MORE "TOP HEAVY" FOR SES 
 
## GROUP VIOLIN PLOTS ## 
      Groups <- Total_Inc_Study$Group_4cat
      map.n <- function(x){return(c(y = median(x)*1.05, label = length(x))) }
      mean.n <- function(x){return(c(y= median(x)*0.97, label = round(mean(x), 2)))}   
     #4 GROUPS:AGE
      ggplot(Total_Inc_Study, aes(x=Groups, y=Age, fill = Groups)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Experimental Groups", y = "Age (years)") + stat_summary(fun.data = mean.n, geom = "text", fun.y = median) + stat_summary(fun.data = mean.n, geom= "text", fun.y=mean, color= "gainsboro") + theme(legend.position="none") 
      #Very similar across groups!

      #4 GROUPS:SES
    ggplot(Total_Inc_Study, aes(x=Groups, y=SES, fill = Groups)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Experimental Groups", y = "SES") + stat_summary(fun.data = mean.n, geom = "text", fun.y = median) + stat_summary(fun.data = mean.n, geom= "text", fun.y=mean, color= "gainsboro") + theme(legend.position="none")
    #ENGLISH GROUPS HIGHER SES/"TOP HEAVY"
    
    #4 GROUPS: AGE OF LANGUAGE EXPOSURE
      AgeLang <- Total_Inc_Study$Age.of.Exposure..mo..Language
      ggplot(Total_Inc_Study, aes(x=Groups, y=AgeLang, fill = Groups)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Experimental Groups", y = "Age of Language Exposure (months)") + scale_fill_grey(start = 0.5, end = 0.9) + stat_summary(fun.data = mean.n, geom = "text", fun = median, vjust=-2) + stat_summary(fun.data = mean.n, geom= "text", fun=mean, color= "black", vjust=-2) + theme(legend.position = "none", axis.title.x = element_text(color="black", size=14, family = "Calibri"), axis.text.x = element_text(color="black", size=12, family = "Calibri"), axis.title.y = element_text(color="black", size=14, family = "Calibri"), axis.text.y = element_text(color="black", size=12, family = "Calibri"))
 
#Timing of language exposure between two later groups, significantly different?
      #Unpaired two-sample t-test resource: http://www.sthda.com/english/wiki/unpaired-two-samples-t-test-in-r
      t.test(EL$Age.of.Exposure..mo..Language,AL$Age.of.Exposure..mo..Language, paired = FALSE, alternative = "two.sided")
      #Welch Two Sample t-test, t = -7.7154, df = 82.959, p-value = 2.398e-11 (significantly different!)

# ANOVA for mean Age and mean SES between groups - is the avergae age or SES sig different between groups?
#AGE#
      # mean Age
      # Ho : mu1=...=mu4
      # Ha : mu2=...≠...mu4
      # alpha level: 0.05     
# RUN THAT ANOVA 
Age_ANOVA <- aov(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Group_4cat)
summary(Age_ANOVA) #p= 0.000379 #NOT EQUAL BETWEEN GROUPS!
      # If > 0.5, conclude that population means for Age are equal between groups
      # If <0.05, reject null, conclude that population means for Age are not equal between groups, which ones differ?
            #Post-Hoc
                  par(ask=TRUE)
                  opar <- par(no.readonly=TRUE) 
                  TukeyHSD(Age_ANOVA)
                  par(las=1) 
                  par(mar=c(5,8,4,2)) 
                  plot(TukeyHSD(Age_ANOVA))
                  par(opar)

# Assumptions to be able to USE ANOVA  
      #1. Normality   - NOT PASS
      qqPlot(Age_ANOVA) #qq plot: scatterplot of observed vs expected normality and want linear line 
      Age_residuals <- residuals(Age_ANOVA) #residual: all data's mean then overall mean subtracted from each data point (indiv-datasetmean)
      shapiro.test(Age_residuals) #do not reject null, assume normality aka bell curve? WANT THAT HIGH P = normally distributed
      #W = 0.95929, p-value = 1.66e-05, NOT NORMALLY DISTRIBUTED!
      ggdensity(Total_Inc_Study$Age_Rounded, main = "Density plot of AGE", xlab = "Age (years)") #NOT A BELL CURVE!
      #BY GROUPS:
      shapiro.test(EE_Inc$Age_Rounded) #p-value = 0.02365<0.05, reject null, can't assume normality
      shapiro.test(AE_Inc$Age_Rounded)#p-value = 0.005251<0.05, reject null, can't assume normality
      shapiro.test(EL_Inc$Age_Rounded)#p-value = 0.002507<0.05, reject null, can't assume normality
      shapiro.test(AL_Inc$Age_Rounded)#p-value = 0.009083<0.05, reject null, can't assume normality

      #2. Homeogeneity of Variances Between Groups    -PASS
      bartlett.test(Total_Inc_Study$Age_Rounded, Total_Inc_Study$Group_4cat) 
      #Bartlett's K-squared = 1.2209, df = 3, p-value = 0.748, HAVE HOMOGENEITY
            # IF p > 0.5 WANT THAT HIGH P! = HOMOGENEITY ACHIEVED
            # IF p<0.05, reject the null hypothesis, do not assume variances are equal, is the variance for each of the groups similar? 
      plot(Age_ANOVA,1) #x-axis all indiv group means and for each group mean has observations and how spread from group mean, want bands to have same spread aka start and end points 
      #PLOT LOOKS GOOD, SIMILAR SPREAD
     
      #BY GROUPS:
      bartlett.test(Age_Rounded ~ Group_4cat, data=Total_Inc_Study) #p-value = 0.748
      leveneTest(Age_Rounded ~ Group_4cat, data=Total_Inc_Study) #p-value = 0.4146

# IF SHAPIRO AND BARLETT ARE >.O5 YAH GOOD, IF NOT: LEVENE AS BACKUP FOR BARLETT, IF STILL NAH, NON-PARAMETRIC METHOD NEEDS TO BE USED / NOT ANOVA 
      # Violated variances assumption, re-run using kruskal-wallis test (non-parametric)
      # IF ASSUMPTIONS DO NOT HOLD, USE KRUSKAL NON-PARAMATRIC TEST/PAIRWISE.WILCOX.TEST FOR POST-HOC)
      kruskal.test(Total_Inc_Study$Age_Rounded ~ Group_4cat, data = Total_Inc_Study)
      #Kruskal-Wallis chi-squared = 17.831, df = 3, p-value = 0.0004767
      pairwise.wilcox.test(Total_Inc_Study$Age_Rounded, Total_Inc_Study$Group_4cat, p.adjust.method="none", paired = FALSE)

*********************************
#SES#
            # mean SES
            # Ho : mu1=...=mu4
            # Ha : mu2=...≠...mu4
            # alpha level: 0.05
            # Assumptions

# All samples drawn independently
SES_ANOVA <- aov(Total_Inc_Study$SES ~ Total_Inc_Study$Group_4cat)
summary(SES_ANOVA) # p = 6.02e-06 #SES MEANS ARE NOT EQUAL BETWEEN GROUPS
      # p=IF>0.05, do not reject null, conclude that population means for SES are equal between groups

      #If different, perform Post-Hoc: 
      par(ask=TRUE)
      opar <- par(no.readonly=TRUE) 
      TukeyHSD(SES_ANOVA)
      par(las=1) 
      par(mar=c(5,8,4,2)) 
      plot(TukeyHSD(SES_ANOVA))
      par(opar)

      #1. Normality  - FAIL
      qqPlot(SES_ANOVA)
      SES_residuals <- residuals(SES_ANOVA) 
      shapiro.test(SES_residuals) #p-value = 1.021e-11 #NOT NORMALLY DISTRIBUTED
      ggdensity(Total_Inc_Study$SES, main = "Density plot of SES", xlab = "SES") #RIGHT SKEWED
      #BY GROUPS: #ALSO ALL < 0.05
            shapiro.test(EE_Inc$SES)
            shapiro.test(EL_Inc$SES) 
            shapiro.test(AE_Inc$SES) 
            shapiro.test(AL_Inc$SES) 
  
      #2. Homeogeneity of Variances Between Groups - PASS
      bartlett.test(Total_Inc_Study$SES, Total_Inc_Study$Group_4cat) # p >0.05, do not reject the null hypothesis, assume variances are equal
      plot(SES_ANOVA,1) #x-axis all indiv group means and for each group mean has observations and how spread from group mean, want bands to have same spread aka start and end points 
      
      bartlett.test(SES ~ Group_4cat, data=Total_Inc_Study) # p-value = 0.2997
      
      leveneTest(SES ~ Group_4cat, data=Total_Inc_Study) #p-value = 0.05584

# IF FAIL ABOVE ASSUMPTIONS, SWITCH TO NON-PARAMETRIC TEST # 
kruskal.test(SES ~ Group_4cat, data = Total_Inc_Study)
pairwise.wilcox.test(Total_Inc_Study$SES,Total_Inc_Study$Group_4cat,p.adjust.method="none")

*************************************************************************************
#Modality
Age_M_ANOVA <- aov(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Modality)
summary(Age_M_ANOVA)  #p=7.01e-05 (not equal!)
Age_M_residuals <- residuals(Age_M_ANOVA)
shapiro.test(Age_M_residuals) #Shapiro-Wilk normality test = W = 0.95778, p-value = 1.147e-05
kruskal.test(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Modality, data = Total_Inc_Study) #p-value = 0.0001087

SES_M_ANOVA <- aov(Total_Inc_Study$SES ~ Total_Inc_Study$Modality)
summary(SES_M_ANOVA)  #p=1.24e-05 (not equal)
SES_M_residuals <- residuals(SES_M_ANOVA)
shapiro.test(SES_M_residuals)  #Shapiro-Wilk normality test = W = 0.88351, p-value = 5.155e-11

#Timing
Age_T_ANOVA <- aov(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Timing)
summary(Age_T_ANOVA) #p = 0.398, NO DIFFERENCE!
Age_T_residuals <- residuals(Age_T_ANOVA) 
shapiro.test(Age_T_residuals) #Shapiro-Wilk normality test = W = 0.94401, p-value = 5.201e-07
kruskal.test(Total_Inc_Study$Age_Rounded ~ Total_Inc_Study$Timing, data = Total_Inc_Study) 

SES_T_ANOVA <- aov(Total_Inc_Study$SES ~ Total_Inc_Study$Timing)
summary(SES_T_ANOVA)  #p = 0.0213, different
SES_T_residuals <- residuals(SES_T_ANOVA)
shapiro.test(SES_T_residuals) #Shapiro-Wilk normality test = W = 0.86037, p-value = 3.031e-12
kruskal.test(Total_Inc_Study$SES ~ Total_Inc_Study$Timing, data = Total_Inc_Study) #p-value = 0.001756


*************************************************************************************
#Analysis

## MAPPING DATA FRAME ## 
  Map_Inc <- Total_Inc_Study #renaming for ease
  View(Map_Inc) #200 kids

#MIXED EFFECTS LOGISTIC REGRESSION
	Map_long <- pivot_longer(data = Map_Inc, cols=c(ends_with("Answer")), names_to = c("Type"), values_to = "Quantity")
	Map_long <- Map_long[,!grepl("^Item",names(Map_long))] # delete columns that contain “item” 
	Map_long <- Map_long[, -c(20:71)]
	View(Map_long) 
	Map_long2 <- pivot_longer(data = Map_Inc, cols=c(ends_with("Correct.")), names_to = c("Type2"), values_to = "Correct")
	Map_long2 <- Map_long2[,!grepl("^Item",names(Map_long2))] # delete columns that contain “item” 
	View(Map_long2)
	Map_longest <- cbind(Map_long, Map_long2$Correct)
	View(Map_longest)
	Map_short <- Map_longest
	View(Map_short)

            # From Type column, create a new column (Map_Pair)
            #Create new column for which IF Map_short$Type contains “NW” or “WN”, assign value “Numeral-Word”
            Map_Pair <- c()
            for(i in 1:10200)
            Map_Pair[i] <- ifelse(grepl("NW", Map_short$Type[i]), "Numeral-Word", ifelse(grepl("WN", Map_short$Type[i]), "Numeral-Word", ifelse(grepl("QN", Map_short$Type[i]), "Quantity-Numeral", ifelse(grepl("NQ", Map_short$Type[i]), "Quantity-Numeral", ifelse(grepl("QW", Map_short$Type[i]), "Quantity-Word", ifelse(grepl("WQ", Map_short$Type[i]), "Quantity-Word","bananas"))))))
            Map_short <- cbind(Map_short, Map_Pair)
            View(Map_short)

            #From Quantity column, create Small, Med, Large
            Set_Size <- c()
            Set_Size <- case_when(Map_short$Quantity <= 3 ~ 'Small',
                                  Map_short$Quantity > 3 & Map_short$Quantity<= 5 ~ 'Medium',
                                  Map_short$Quantity > 5 ~ 'Large')
            Map_short <- cbind(Map_short,Set_Size)
	    names(Map_short)[names(Map_short) == "Map_long2$Correct"] <- "Correct"
            View(Map_short)

            #Running Mixed Effects Logistic Regression
            MixReg <- glmer(Correct ~ Age_Rounded + SES + Set_Size + Map_Pair + Age.of.Exposure..mo..Language + (1 | SUBJECT_ID), data = Map_short, family = binomial, control = glmerControl(optimizer ="bobyqa"), nAGQ = 10)
            summary(MixReg)
            #Obtain Model Descriptives
            se <- sqrt(diag(vcov(MixReg)))
            (tab <- cbind(Est = fixef(MixReg), LL = fixef(MixReg) - 1.96 * se, UL = fixef(MixReg) + 1.96 * se))
            exp(tab) #provides odds ratios
	    
	    #References (change Set Size and Map Pair)
	    Map_short$SetSize_refM <- as.factor(factor(as.character(Map_short$Set_Size), levels=c("Medium", "Small", "Large"), exclude=""))
	    Map_short$MapPair_refQW <- as.factor(factor(as.character(Map_short$Map_Pair), levels=c("Quantity-Word","Numeral-Word","Quantity-Numeral"), exclude=""))
	    View(Map_short)
	    MixReg_Ref <- glmer(Correct ~ Age_Rounded + SES + SetSize_refM + MapPair_refQW + Age.of.Exposure..mo..Language + (1 | SUBJECT_ID), data = Map_short, family = binomial, control = glmerControl(optimizer ="bobyqa"), nAGQ = 10)
            summary(MixReg_Ref)
	    se <- sqrt(diag(vcov(MixReg_Ref)))
            (tab2 <- cbind(Est = fixef(MixReg_Ref), LL = fixef(MixReg_Ref) - 1.96 * se, UL = fixef(MixReg) + 1.96 * se))
            exp(tab2)

#OVERALL
#Create 4 group data frames
EE <- subset(Map_Inc, Map_Inc$Group_4cat == "English Early")
EL <- subset(Map_Inc, Map_Inc$Group_4cat == "English Later")
AE <- subset(Map_Inc, Map_Inc$Group_4cat == "ASL Early")
AL <- subset(Map_Inc, Map_Inc$Group_4cat == "ASL Later")

#Overall Performance compared to chance for each group, all p < 0.001
wilcox.test(EE$AvgCorrect_Total, mu = .25, alternative = "greater") #V = 1176, p-value = 7.702e-10
wilcox.test(EL$AvgCorrect_Total, mu = .25, alternative = "greater") #V = 1128, p-value = 1.178e-09
wilcox.test(AE$AvgCorrect_Total, mu = .25, alternative = "greater") #V = 1275, p-value = 3.419e-10
wilcox.test(AL$AvgCorrect_Total, mu = .25, alternative = "greater") #V = 1485, p-value = 7.906e-11

#Performance at Ceiling per group
EE_Ceil <- EE$SumCorrectTotal_All
EE_All <- 51 #ceiling performance 
Var_EE <- length(which(EE_Ceil>= EE_All)) #number of observations equal to ceiling 
N <- nrow(EE) #number of total observations
(Var_EE/N)*100 #18.75% at ceiling

EL_Ceil <- EL$SumCorrectTotal_All
EL_All <- 51 #ceiling performance 
Var_EL <- length(which(EL_Ceil>= EL_All)) #number of observations equal to ceiling 
N <- nrow(EL) #number of total observations
(Var_EL/N)*100 #12.77% at ceiling

AE_Ceil <- AE$SumCorrectTotal_All
AE_All <- 51 #ceiling performance 
Var_AE <- length(which(AE_Ceil>= AE_All)) #number of observations equal to ceiling 
N <- nrow(AE) #number of total observations
(Var_AE/N)*100 #26% at ceiling

AL_Ceil <- AL$SumCorrectTotal_All
AL_All <- 51 #ceiling performance 
Var_AL <- length(which(AL_Ceil>= AL_All)) #number of observations equal to ceiling 
N <- nrow(AL) #number of total observations
(Var_AL/N)*100 #20% at ceiling


#ANOVAS, Overall Performance
#Create Shortened Variables
M_SumTotalCorr <- Map_Inc$SumCorrectTotal_All
M_Age <- Map_Inc$Age_Rounded
M_SES <- Map_Inc$SES
M_Grps <- Map_Inc$Group_4cat
M_Tim <- Map_Inc$Timing
M_Mod <- Map_Inc$Modality
M_Lang <- Map_Inc$Age.of.Exposure..mo..Language
map.n <- function(x){return(c(y = median(x)*1.05, label = length(x))) }
mean.n <- function(x){return(c(y= median(x)*0.97, label = round(mean(x), 2)))}   

      #4 Groups
      aov_grps<- aov(Map_Inc$AvgCorrect_Total ~ Map_Inc$Group_4cat)
      summary(aov_grps)  #p-value = 0.0053, df = 3, f = 4.366
      tuk_grps<- TukeyHSD(aov_grps)
      tuk_grps
      mean(EE$AvgCorrect_Total) #0.92
      mean(EL$AvgCorrect_Total) #0.88
      mean(AE$AvgCorrect_Total) #0.92
      mean(AL$AvgCorrect_Total) #0.85
      ggplot(Map_Inc, aes(x=M_Grps, y=M_SumTotalCorr, fill = M_Grps)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Experimental Groups", y = "Total Correct (out of 51)") + scale_fill_grey(start = 0.5, end = 0.9) + stat_summary(fun.data = mean.n, geom = "text", fun = median) + stat_summary(fun.data = mean.n, geom= "text", fun=mean, color= "black") + theme(legend.position = "none", axis.title.x = element_text(color="black", size=14, family = "Calibri"), axis.text.x = element_text(color="black", size=12, family = "Calibri"), axis.title.y = element_text(color="black", size=14, family = "Calibri"), axis.text.y = element_text(color="black", size=12, family = "Calibri"))

     #Modality
      aov_mod<- aov(Map_Inc$AvgCorrect_Total ~ Map_Inc$Modality)
      summary(aov_mod) #p = 0.46, df = 1, f = 0.548 #Not differ by modality!
      ASL <- subset(Map_Inc, Map_Inc$Modality == "ASL")
      View(ASL)
      mean(ASL$AvgCorrect_Total) #0.88
      English <- subset(Map_Inc, Map_Inc$Modality == "English")
      View(English)
      mean(English$AvgCorrect_Total) #0.90
      ggplot(Map_Inc, aes(x=M_Mod, y=M_SumTotalCorr, fill = M_Mod)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Language Modality", y = "Total Correct (out of 51)") + scale_fill_grey(start = 0.5, end = 0.9) + stat_summary(fun.data = mean.n, geom = "text", fun = median) + stat_summary(fun.data = mean.n, geom= "text", fun=mean, color= "black") + theme(legend.position = "none", axis.title.x = element_text(color="black", size=14, family = "Calibri"), axis.text.x = element_text(color="black", size=12, family = "Calibri"), axis.title.y = element_text(color="black", size=14, family = "Calibri"), axis.text.y = element_text(color="black", size=12, family = "Calibri"))

      #Timing
      aov_tim<- aov(Map_Inc$AvgCorrect_Total ~ Map_Inc$Timing)
      summary(aov_tim) #p = 0.000856, df = 1, f = 11.46 #differ by timing! 
      Early <- subset(Map_Inc, Map_Inc$Timing == "Early")
      View (Early)
      mean(Early$AvgCorrect_Total) #0.92
      Later <- subset(Map_Inc, Map_Inc$Timing == "Later")
      View (Later)
      mean(Later$AvgCorrect_Total) #0.86
      ggplot(Map_Inc, aes(x=M_Tim, y=M_SumTotalCorr, fill = M_Tim)) + geom_violin() + geom_boxplot(width = 0.2) + labs (x= "Language Timing", y = "Total Correct (out of 51)") + scale_fill_grey(start = 0.5, end = 0.9) + stat_summary(fun.data = mean.n, geom = "text", fun = median) + stat_summary(fun.data = mean.n, geom= "text", fun=mean, color= "black") + theme(legend.position = "none", axis.title.x = element_text(color="black", size=14, family = "Calibri"), axis.text.x = element_text(color="black", size=12, family = "Calibri"), axis.title.y = element_text(color="black", size=14, family = "Calibri"), axis.text.y = element_text(color="black", size=12, family = "Calibri"))

# BREAKING DOWN BY MAPPING PAIRS
QW <- Map_Inc$Sum_Quantity.Word_Word.Quantity
QN <- Map_Inc$Sum_Quantity.Numeral_Numeral.Quantity
NW <- Map_Inc$Sum_Numeral.Word_Word.Numeral
Map_Inc <- data.frame(Map_Inc,QW, QN, NW)
View(Map_Inc)

      #Experimental Groups by Mapping Pairs
      BoxDF <- data.frame(QW,QN,NW,Map_Inc$Group_4cat)
      View(BoxDF)
      groups.data <- melt(BoxDF, id.vars='Map_Inc.Group_4cat')
      View(groups.data)
      groups.data$Map_Inc.Group_4cat <- factor(groups.data$Map_Inc.Group_4cat, levels = c("English Early", "ASL Early", "English Later", "ASL Later")) #order we want to present data
      groups_map <- ggplot(groups.data, aes(variable, value, fill=Map_Inc.Group_4cat)) + geom_boxplot() + labs(x="Map Pairs", y="Accuracy (out of 17)", fill = "Experimental Groups") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + scale_fill_grey(start = 0.5, end = 0.9) + theme(plot.title = element_text(color="black", size=14, family = "Calibri"), axis.title.x = element_text(color="black", size=14, family = "Calibri"), axis.text.x = element_text(color="black", size=12, family = "Calibri"), axis.title.y = element_text(color="black", size=14, family = "Calibri"), axis.text.y = element_text(color="black", size=12, family = "Calibri"), legend.title = element_text(color="black", size=14, family = "Calibri"), legend.text = element_text(color="black", size=14, family = "Calibri"))
      groups_map
     
      All_NW <- subset(groups.data, groups.data$variable == "NW")
      View(All_NW)
      aov_grpsNW<- aov(All_NW$value ~ All_NW$Map_Inc.Group_4cat)
      summary(aov_grpsNW) #p = 0.508, df = 3, f = 0.777  #NW performance DOES NOT DIFFER by 4 groups
      mean(EE$Sum_Numeral.Word_Word.Numeral) #16.44
      mean(AE$Sum_Numeral.Word_Word.Numeral) #16.32
      mean(EL$Sum_Numeral.Word_Word.Numeral) #16.23
      mean(AL$Sum_Numeral.Word_Word.Numeral) #15.95
      
      All_QW <- subset(groups.data, groups.data$variable == "QW")
      View(All_QW)
      aov_grpsQW<- aov(All_QW$value ~ All_QW$Map_Inc.Group_4cat)
      summary(aov_grpsQW) #p =0.00785, df = 3, f = 4.067, #QW performance DIFFERS by 4 groups
      tuk_grpsQW<- TukeyHSD(aov_grpsQW)
      tuk_grpsQW
      mean(EE$Sum_Quantity.Word_Word.Quantity) #14.90
      mean(AE$Sum_Quantity.Word_Word.Quantity) #15.16
      mean(EL$Sum_Quantity.Word_Word.Quantity) #14.04
      mean(AL$Sum_Quantity.Word_Word.Quantity) #13.55

      All_QN <- subset(groups.data, groups.data$variable == "QN")
      View(All_QN)
      aov_grpsQN<- aov(All_QN$value ~ All_QN$Map_Inc.Group_4cat)
      summary(aov_grpsQN) #p =0.00279, df = 3, f = 4.855, QN performance DIFFERS by 4 groups
      tuk_grpsQN<- TukeyHSD(aov_grpsQN)
      tuk_grpsQN
      mean(EE$Sum_Quantity.Numeral_Numeral.Quantity) #15.40
      mean(AE$Sum_Quantity.Numeral_Numeral.Quantity) #15.66
      mean(EL$Sum_Quantity.Numeral_Numeral.Quantity) #14.49
      mean(AL$Sum_Quantity.Numeral_Numeral.Quantity) #13.74

      #TIMING by Mapping Pairs      
      BoxDF_Timing <- data.frame(QW,QN,NW,Map_Inc$Timing)
      View(BoxDF_Timing)
      timing.data <- melt(BoxDF_Timing, id.vars='Map_Inc.Timing')
      View(timing.data)
      timing_map <- ggplot(timing.data, aes(variable, value, fill=Map_Inc.Timing)) + geom_boxplot() + scale_fill_manual(values=c("grey87", "grey51"), labels = c("Early", "Later")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=20, family="Calibri"))
      timing_map
      
      Tim_NW <- subset(timing.data, timing.data$variable == "NW")
      View(Tim_NW)
      aov_timNW<- aov(Tim_NW$value ~ Tim_NW$Map_Inc.Timing)
      summary(aov_timNW) #p = 0.22, df = 1, f =  1.515, NW DOES NOT DIFFER by timing
      mean(Early$Sum_Numeral.Word_Word.Numeral) #16.38
      mean(Later$Sum_Numeral.Word_Word.Numeral) #16.08

      Tim_QW <- subset(timing.data, timing.data$variable == "QW")
      View(Tim_QW)
      aov_timQW<- aov(Tim_QW$value ~ Tim_QW$Map_Inc.Timing)
      summary(aov_timQW) #p = 0.00101, df =1, f = 11.13 #QW DOES DIFFER by timing
	mean(Early$Sum_Quantity.Word_Word.Quantity) #15.03
      mean(Later$Sum_Quantity.Word_Word.Quantity) #13.77

      Tim_QN <- subset(timing.data, timing.data$variable == "QN")
      View(Tim_QN)
      aov_timQN<- aov(Tim_QN$value ~ Tim_QN$Map_Inc.Timing)
      summary(aov_timQN) #p = 0.000468, df =1, f = 12.66 #QN DOES DIFFER by timing
      mean(Early$Sum_Quantity.Numeral_Numeral.Quantity) #15.53
      mean(Later$Sum_Quantity.Numeral_Numeral.Quantity) #14.09

      #MODALITY by Mapping Pairs
      BoxDF_Modality <- data.frame(QW,QN,NW,Map_Inc$Modality)
      View(BoxDF_Modality)
      modality.data <- melt(BoxDF_Modality, id.vars='Map_Inc.Modality')
      View(modality.data)
      modality_map <- ggplot(modality.data, aes(variable, value, fill=Map_Inc.Modality)) + geom_boxplot() + scale_fill_manual(values=c("grey87", "grey51"), labels = c("English", "ASL")) + labs( y="Accuracy (out of 17)") + scale_y_continuous (breaks=c(7,8,9,10,11,12,13,14,15,16,17), limits = c(7,17), expand = c(0,0)) + scale_x_discrete(limits=c("QN","QW","NW"), expand = c(.2,0),labels = c("Quantity-Numeral", "Quantity-Word", "Numeral-Word")) + theme_bw() + theme(legend.position="top", legend.title = element_blank(), axis.title.x=element_blank(), panel.border = element_blank(),panel.grid.minor.y = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size=20, family="Calibri"))
      modality_map

      Mod_NW <- subset(modality.data, modality.data$variable == "NW")
      View(Mod_NW)
      aov_modNW<- aov(Mod_NW$value ~ Mod_NW$Map_Inc.Modality)
      summary(aov_modNW) #p = 0.383, df = 1, f =  0.764, NW DOES NOT DIFFER by modality
      mean(ASL$Sum_Numeral.Word_Word.Numeral) #16.12
      mean(English$Sum_Numeral.Word_Word.Numeral) #16.34
      
      Mod_QW <- subset(modality.data, modality.data$variable == "QW")
      View(Mod_QW)
      aov_modQW<- aov(Mod_QW$value ~ Mod_QW$Map_Inc.Modality)
      summary(aov_modQW) #p = 0.681, df = 1, f =  0.169, QW DOES NOT DIFFER by modality
      mean(ASL$Sum_Quantity.Word_Word.Quantity) #14.31
      mean(English$Sum_Quantity.Word_Word.Quantity) #14.47

      Mod_QN <- subset(modality.data, modality.data$variable == "QN")
      View(Mod_QN)
      aov_modQN<- aov(Mod_QN$value ~ Mod_QN$Map_Inc.Modality)
      summary(aov_modQN) #p = 0.488, df = 1, f =  0.482, QN DOES NOT DIFFER by modality
      mean(ASL$Sum_Quantity.Numeral_Numeral.Quantity) #14.66
      mean(English$Sum_Quantity.Numeral_Numeral.Quantity) #14.95


#Mixed Effects Logistic Regressions testing timing and modality
	MixReg_MT <- glmer(Correct ~ Modality + Timing + (1 | SUBJECT_ID), data = Map_short, family = binomial, control = glmerControl(optimizer ="bobyqa"), nAGQ = 10)
	summary(MixReg_MT)
	NW_reg <- subset(Map_short, Map_short$Map_Pair == "Numeral-Word")
	View(NW_reg)
	MixReg_MT_NW <- glmer(Correct ~ Modality + Timing + (1 | SUBJECT_ID), data = NW_reg, family = binomial, control = glmerControl(optimizer ="bobyqa"), nAGQ = 10)
	summary(MixReg_MT_NW)

	QW_reg <- subset(Map_short, Map_short$Map_Pair == "Quantity-Word")
	View(QW_reg)
	MixReg_MT_QW <- glmer(Correct ~ Modality + Timing + (1 | SUBJECT_ID), data = QW_reg, family = binomial, control = glmerControl(optimizer ="bobyqa"), nAGQ = 10)
	summary(MixReg_MT_QW)

	QN_reg <- subset(Map_short, Map_short$Map_Pair == "Quantity-Numeral")
	View(QN_reg)
	MixReg_MT_QN <- glmer(Correct ~ Modality + Timing + (1 | SUBJECT_ID), data = QN_reg, family = binomial, control = glmerControl(optimizer ="bobyqa"), nAGQ = 10)
	summary(MixReg_MT_QN)


#AGE SCATTERPLOTS
#Scatterplots of Overall Performance by Timing
ggplot(Map_Inc, aes(x=Age_Rounded, y=AvgCorrect_Total)) + geom_point(aes(shape=Timing, colour=Timing), position=jitter, size=2) + geom_smooth(aes(colour=Timing, fill=Timing), method="loess", show.legend = FALSE) + labs(x="Age (years)", y="Overall Proportion Correct") + scale_shape_manual(name="Timing of \nLanguage Exposure", labels=c("Early", "Later"), values=c(17, 15)) + scale_color_manual(name="Timing of \nLanguage Exposure", labels=c("Early", "Later"), values=c("red","blue")) + theme(text = element_text(size=16, family="Calibri")) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))

#Scatterplots of Overall Performance by Modality
ggplot(Map_Inc, aes(x=Age_Rounded, y=AvgCorrect_Total)) + geom_point(aes(shape=Modality, colour=Modality), position=jitter, size=2) + geom_smooth(aes(colour=Modality, fill=Modality), method="loess", show.legend = FALSE) + labs(x="Age (years)", y="Overall Proportion Correct") + scale_shape_manual(name="Language Modality", labels=c("ASL", "English"), values=c(17, 15)) + scale_color_manual(name="Language Modality", labels=c("ASL", "English"), values=c("red","blue")) + theme(text = element_text(size=16, family="Calibri")) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))


#Scatterplot by age with data for QW and QN only (b/c sig)
P_QW <- Map_Inc$AvgCorrect_Quantity.Word_Word.Quantity
P_QN <- Map_Inc$AvgCorrect_Quantity.Numeral_Numeral.Quantity
AgeTim <- data.frame(P_QW,P_QN,Map_Inc$Timing, Map_Inc$Age_Rounded)
View(AgeTim)
agetim.data <- melt(AgeTim, id.vars=c("Map_Inc.Timing", "Map_Inc.Age_Rounded"))
View(agetim.data)
ggplot(agetim.data, aes(x=Map_Inc.Age_Rounded, y=value)) + geom_point(aes(shape=Map_Inc.Timing, colour=Map_Inc.Timing), position=jitter, size=2) + geom_smooth(aes(colour=Map_Inc.Timing, fill=Map_Inc.Timing), method="loess", show.legend = FALSE) + labs(x="Age (years)", y="Proportion Correct") + scale_shape_manual(name="Timing of \nLanguage Exposure", labels=c("Early", "Later"), values=c(17, 15)) + scale_color_manual(name="Timing of \nLanguage Exposure", labels=c("Early", "Later"), values=c("red","blue")) + theme(text = element_text(size=16, family="Calibri")) + coord_cartesian(xlim = c(5, 10), ylim= c(0.4,1)) + scale_y_continuous(breaks=c(0.5, 0.6, 0.7, 0.8, 0.9, 1)) + scale_x_continuous(breaks=c(5, 6, 7, 8, 9))

